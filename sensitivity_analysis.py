#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
================================================================================
US Tech Stock - åƒæ•¸æ•æ„Ÿåº¦åˆ†æ (Parameter Sensitivity Analysis)
================================================================================
é‡å° PLTR, NVDA, TSLA, NFLX åŸ·è¡Œåƒæ•¸ç¶²æ ¼æœå°‹ï¼Œé‡åŒ–åœæ/åœåˆ©åƒæ•¸å°ç¸¾æ•ˆçš„å½±éŸ¿ã€‚

åƒæ•¸ç¶²æ ¼ (75 çµ„åˆ):
- HARD_STOP_PCT: [-3%, -4%, -5%, -6%, -8%]
- CALLBACK_BASE: [-3%, -4%, -5%, -6%, -8%]
- CALLBACK_HIGH: [-7%, -9%, -11%]

è¼¸å‡º:
- sensitivity_analysis_results.csv: å®Œæ•´åƒæ•¸çµ„åˆçµæœ
- sensitivity_heatmap_{ticker}.png: åƒæ•¸ç†±åœ–
- sensitivity_best_params.csv: æœ€ä½³åƒæ•¸çµ„åˆ

ä½œè€…ï¼šPhil Liang (Generated by Gemini)
æ—¥æœŸï¼š2026-01-18
================================================================================
"""

import os
import sys
import json
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from tqdm import tqdm
from itertools import product

if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

from train_us_tech_buy_agent import (
    load_or_update_local_csv,
    calculate_features,
    BENCHMARK, FEATURE_COLS, VAL_RANGE, MODELS_PATH
)

from stable_baselines3 import PPO


# =============================================================================
# åƒæ•¸è¨­å®š
# =============================================================================
TARGET_TICKERS = ["PLTR", "NVDA", "TSLA", "NFLX"]
VAL_START, VAL_END = VAL_RANGE
INITIAL_CAPITAL = 1_000_000
CONFIDENCE_THRESHOLD = 0.90
TRAILING_ACTIVATION = 0.15  # å›ºå®šå€¼
HIGH_PROFIT_THR = 0.25

# åƒæ•¸ç¶²æ ¼
HARD_STOP_GRID = [-0.03, -0.04, -0.05, -0.06, -0.08]
CALLBACK_BASE_GRID = [0.03, 0.04, 0.05, 0.06, 0.08]
CALLBACK_HIGH_GRID = [0.07, 0.09, 0.11]

OUTPUT_DIR = "sensitivity_results"


# =============================================================================
# æ¨¡å‹ç›¸é—œ
# =============================================================================
def load_model_manifest(models_path: str) -> dict:
    manifest_path = os.path.join(models_path, "model_manifest.json")
    if not os.path.exists(manifest_path):
        return None
    with open(manifest_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_ticker_model(ticker: str, manifest: dict) -> PPO:
    if ticker not in manifest.get("tickers", {}):
        return None
    model_path = manifest["tickers"][ticker]["model_path"]
    if not os.path.exists(model_path):
        return None
    return PPO.load(model_path, device="cpu")


def get_action_confidence(model: PPO, obs: np.ndarray) -> tuple:
    obs_tensor = torch.as_tensor(obs.reshape(1, -1), dtype=torch.float32)
    with torch.no_grad():
        distribution = model.policy.get_distribution(obs_tensor)
        probs = distribution.distribution.probs.numpy()[0]
        action, _ = model.predict(obs, deterministic=True)
        return int(action), float(probs[1])


# =============================================================================
# å›æ¸¬å¼•æ“ (åƒæ•¸åŒ–ç‰ˆæœ¬)
# =============================================================================
def run_backtest_with_params(ticker: str, model: PPO, features_df: pd.DataFrame,
                              hard_stop: float, callback_base: float, callback_high: float) -> dict:
    """
    åŸ·è¡Œå–®æ¬¡å›æ¸¬ (å¯è‡ªå®šç¾©åƒæ•¸)
    
    Args:
        hard_stop: ç¡¬æ€§åœæ (e.g., -0.08)
        callback_base: ä¸€èˆ¬å›æª”åœåˆ© (e.g., 0.08)
        callback_high: é«˜ç²åˆ©å›æª”åœåˆ© (e.g., 0.11)
    
    Returns:
        dict: ç¸¾æ•ˆæŒ‡æ¨™
    """
    # éæ¿¾æ¸¬è©¦æœŸé–“
    test_df = features_df[
        (features_df.index >= pd.Timestamp(VAL_START)) &
        (features_df.index <= pd.Timestamp(VAL_END))
    ].copy()
    
    if len(test_df) == 0:
        return None
    
    capital = INITIAL_CAPITAL
    position = None
    equity_curve = []
    trades = []
    
    dates = test_df.index.tolist()
    closes = test_df['Close'].values
    features = test_df[FEATURE_COLS].values.astype(np.float32)
    
    for i in range(len(test_df)):
        date = dates[i]
        price = closes[i]
        
        # è¨˜éŒ„æ·¨å€¼
        if position:
            current_value = capital + position['shares'] * price
        else:
            current_value = capital
        equity_curve.append(current_value)
        
        # æŒæœ‰ä¸­ï¼šæª¢æŸ¥å‡ºå ´
        if position is not None:
            buy_price = position['buy_price']
            current_return = price / buy_price - 1
            highest_return = position['highest_price'] / buy_price - 1
            drawdown_from_high = (position['highest_price'] - price) / position['highest_price']
            
            if price > position['highest_price']:
                position['highest_price'] = price
            
            sell_reason = None
            
            # ç¡¬æ€§åœæ
            if current_return <= hard_stop:
                sell_reason = "Hard Stop"
            # ç§»å‹•åœåˆ©
            elif highest_return >= TRAILING_ACTIVATION:
                if highest_return >= HIGH_PROFIT_THR:
                    cb_limit = callback_high
                else:
                    cb_limit = callback_base
                
                if drawdown_from_high >= cb_limit:
                    sell_reason = "Trailing Stop"
            
            if sell_reason:
                sell_value = position['shares'] * price
                capital += sell_value
                trades.append({
                    'return': current_return,
                    'exit_reason': sell_reason
                })
                position = None
        
        # ç©ºæ‰‹ï¼šæª¢æŸ¥é€²å ´
        elif position is None:
            obs = features[i]
            action, confidence = get_action_confidence(model, obs)
            
            if action == 1 and confidence > CONFIDENCE_THRESHOLD:
                invest_amount = capital * 0.95
                shares = int(invest_amount / price)
                
                if shares > 0:
                    cost = shares * price
                    capital -= cost
                    position = {
                        'shares': shares,
                        'buy_price': price,
                        'buy_idx': i,
                        'highest_price': price
                    }
    
    # å¼·åˆ¶å¹³å€‰
    if position is not None:
        final_price = closes[-1]
        sell_value = position['shares'] * final_price
        capital += sell_value
        current_return = final_price / position['buy_price'] - 1
        trades.append({'return': current_return, 'exit_reason': 'End'})
    
    # è¨ˆç®—æŒ‡æ¨™
    if len(equity_curve) == 0:
        return None
    
    equity = np.array(equity_curve)
    initial = INITIAL_CAPITAL
    final = equity[-1]
    total_return = (final - initial) / initial
    
    days = (test_df.index[-1] - test_df.index[0]).days
    years = days / 365.0
    cagr = (1 + total_return) ** (1 / years) - 1 if years > 0 else 0
    
    daily_returns = np.diff(equity) / equity[:-1]
    if len(daily_returns) > 0 and np.std(daily_returns) > 0:
        sharpe = (np.mean(daily_returns) * 252 - 0.02) / (np.std(daily_returns) * np.sqrt(252))
    else:
        sharpe = 0
    
    rolling_max = np.maximum.accumulate(equity)
    drawdown = (equity - rolling_max) / rolling_max
    max_drawdown = np.min(drawdown)
    
    win_rate = sum(1 for t in trades if t['return'] > 0) / len(trades) if trades else 0
    
    return {
        'ticker': ticker,
        'hard_stop': hard_stop,
        'callback_base': callback_base,
        'callback_high': callback_high,
        'total_return': total_return,
        'cagr': cagr,
        'sharpe': sharpe,
        'mdd': max_drawdown,
        'trades': len(trades),
        'win_rate': win_rate,
        'return_mdd_ratio': abs(total_return / max_drawdown) if max_drawdown != 0 else 0
    }


# =============================================================================
# ç¶²æ ¼æœå°‹
# =============================================================================
def run_grid_search(ticker: str, model: PPO, features_df: pd.DataFrame) -> list:
    """å°å–®ä¸€è‚¡ç¥¨åŸ·è¡Œç¶²æ ¼æœå°‹"""
    results = []
    
    param_combinations = list(product(HARD_STOP_GRID, CALLBACK_BASE_GRID, CALLBACK_HIGH_GRID))
    
    for hard_stop, callback_base, callback_high in tqdm(param_combinations, 
                                                         desc=f"  Grid Search {ticker}", leave=False):
        result = run_backtest_with_params(
            ticker, model, features_df,
            hard_stop, callback_base, callback_high
        )
        if result:
            results.append(result)
    
    return results


# =============================================================================
# è¦–è¦ºåŒ–
# =============================================================================
def plot_heatmap(results_df: pd.DataFrame, ticker: str, output_dir: str):
    """ç¹ªè£½å¤æ™®å€¼ç†±åœ–"""
    # éæ¿¾è©²è‚¡ç¥¨ï¼Œå›ºå®š CALLBACK_HIGH = 0.11
    df = results_df[(results_df['ticker'] == ticker) & (results_df['callback_high'] == 0.11)]
    
    if len(df) == 0:
        return
    
    # Pivot for heatmap
    pivot = df.pivot_table(
        values='sharpe', 
        index='hard_stop', 
        columns='callback_base',
        aggfunc='mean'
    )
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Sharpe Heatmap
    sns.heatmap(pivot, annot=True, fmt='.2f', cmap='RdYlGn', center=0,
                ax=axes[0], cbar_kws={'label': 'Sharpe Ratio'})
    axes[0].set_title(f'{ticker} - Sharpe Ratio\n(CALLBACK_HIGH=11%)', fontsize=12)
    axes[0].set_xlabel('Callback Base (%)', fontsize=10)
    axes[0].set_ylabel('Hard Stop (%)', fontsize=10)
    axes[0].set_xticklabels([f'{x*100:.0f}%' for x in pivot.columns])
    axes[0].set_yticklabels([f'{x*100:.0f}%' for x in pivot.index])
    
    # Return/MDD Ratio Heatmap
    pivot2 = df.pivot_table(
        values='return_mdd_ratio', 
        index='hard_stop', 
        columns='callback_base',
        aggfunc='mean'
    )
    
    sns.heatmap(pivot2, annot=True, fmt='.2f', cmap='Blues',
                ax=axes[1], cbar_kws={'label': 'Return/MDD Ratio'})
    axes[1].set_title(f'{ticker} - Return/MDD Ratio\n(CALLBACK_HIGH=11%)', fontsize=12)
    axes[1].set_xlabel('Callback Base (%)', fontsize=10)
    axes[1].set_ylabel('Hard Stop (%)', fontsize=10)
    axes[1].set_xticklabels([f'{x*100:.0f}%' for x in pivot2.columns])
    axes[1].set_yticklabels([f'{x*100:.0f}%' for x in pivot2.index])
    
    plt.tight_layout()
    chart_path = os.path.join(output_dir, f"sensitivity_heatmap_{ticker}.png")
    plt.savefig(chart_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  âœ… ç†±åœ–å·²å„²å­˜: {chart_path}")


def plot_3d_surface(results_df: pd.DataFrame, ticker: str, output_dir: str):
    """ç¹ªè£½ 3D è¡¨é¢åœ–"""
    from mpl_toolkits.mplot3d import Axes3D
    
    df = results_df[(results_df['ticker'] == ticker) & (results_df['callback_high'] == 0.11)]
    
    if len(df) == 0:
        return
    
    fig = plt.figure(figsize=(12, 8))
    ax = fig.add_subplot(111, projection='3d')
    
    X = df['hard_stop'].values * 100  # è½‰ç‚ºç™¾åˆ†æ¯”
    Y = df['callback_base'].values * 100
    Z = df['sharpe'].values
    
    ax.scatter(X, Y, Z, c=Z, cmap='RdYlGn', s=50, alpha=0.8)
    
    ax.set_xlabel('Hard Stop (%)', fontsize=10)
    ax.set_ylabel('Callback Base (%)', fontsize=10)
    ax.set_zlabel('Sharpe Ratio', fontsize=10)
    ax.set_title(f'{ticker} - Parameter Sensitivity 3D View', fontsize=12)
    
    plt.tight_layout()
    chart_path = os.path.join(output_dir, f"sensitivity_3d_{ticker}.png")
    plt.savefig(chart_path, dpi=150, bbox_inches='tight')
    plt.close()


# =============================================================================
# çµæœåˆ†æ
# =============================================================================
def find_best_params(results_df: pd.DataFrame, mdd_threshold: float = -0.40) -> pd.DataFrame:
    """æ‰¾å‡ºæœ€ä½³åƒæ•¸çµ„åˆ"""
    # é€æ­¥æ”¾å¯¬ MDD æ¢ä»¶ç›´åˆ°æœ‰çµæœ
    thresholds = [mdd_threshold, -0.50, -0.60, -0.70, -0.80, -1.0]
    
    for thr in thresholds:
        filtered = results_df[results_df['mdd'] >= thr].copy()
        if len(filtered) > 0:
            if thr != mdd_threshold:
                print(f"  âš ï¸ MDD >= {mdd_threshold:.0%} ç„¡çµæœï¼Œæ”¾å¯¬è‡³ >= {thr:.0%}")
            # æŒ‰ Sharpe æ’åºï¼Œå–å‰ 10
            best = filtered.nlargest(10, 'sharpe')
            return best
    
    # è‹¥ä»ç„¡çµæœï¼Œè¿”å› Sharpe æœ€é«˜çš„
    return results_df.nlargest(10, 'sharpe')


def compare_with_baseline(results_df: pd.DataFrame, output_dir: str):
    """èˆ‡åŸå§‹åƒæ•¸æ¯”è¼ƒ"""
    baseline = results_df[
        (results_df['hard_stop'] == -0.08) &
        (results_df['callback_base'] == 0.08) &
        (results_df['callback_high'] == 0.11)
    ]
    
    print("\n" + "=" * 80)
    print("ğŸ“Š åŸå§‹åƒæ•¸ (-8%/-8%/-11%) ç¸¾æ•ˆ")
    print("=" * 80)
    
    for _, row in baseline.iterrows():
        print(f"  {row['ticker']:>6}: Return={row['total_return']:>7.1%} | MDD={row['mdd']:>7.1%} | Sharpe={row['sharpe']:>5.2f}")
    
    # æ‰¾å‡ºå„è‚¡ç¥¨æœ€ä½³åƒæ•¸
    print("\n" + "=" * 80)
    print("ğŸ“Š æœ€ä½³åƒæ•¸çµ„åˆ (MDD >= -40% ä¸” Sharpe æœ€é«˜)")
    print("=" * 80)
    
    recommendations = []
    
    for ticker in TARGET_TICKERS:
        ticker_results = results_df[results_df['ticker'] == ticker]
        best = find_best_params(ticker_results, mdd_threshold=-0.40)
        
        if len(best) > 0:
            top = best.iloc[0]
            baseline_row = baseline[baseline['ticker'] == ticker]
            
            if len(baseline_row) > 0:
                mdd_improvement = top['mdd'] - baseline_row.iloc[0]['mdd']
            else:
                mdd_improvement = 0
            
            print(f"\n  {ticker}:")
            print(f"    Hard Stop: {top['hard_stop']:.0%} | Callback Base: {top['callback_base']:.0%} | Callback High: {top['callback_high']:.0%}")
            print(f"    Return: {top['total_return']:.1%} | MDD: {top['mdd']:.1%} | Sharpe: {top['sharpe']:.2f}")
            print(f"    MDD æ”¹å–„: {mdd_improvement:+.1%}")
            
            recommendations.append({
                'Ticker': ticker,
                'Hard_Stop': f"{top['hard_stop']:.0%}",
                'Callback_Base': f"{top['callback_base']:.0%}",
                'Callback_High': f"{top['callback_high']:.0%}",
                'Total_Return': f"{top['total_return']:.1%}",
                'MDD': f"{top['mdd']:.1%}",
                'Sharpe': f"{top['sharpe']:.2f}",
                'MDD_Improvement': f"{mdd_improvement:+.1%}"
            })
    
    # å„²å­˜å»ºè­°
    rec_df = pd.DataFrame(recommendations)
    rec_path = os.path.join(output_dir, "sensitivity_best_params.csv")
    rec_df.to_csv(rec_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… æœ€ä½³åƒæ•¸å»ºè­°å·²å„²å­˜: {rec_path}")
    
    return rec_df


# =============================================================================
# ä¸»ç¨‹å¼
# =============================================================================
def main():
    print("=" * 70)
    print("  US Tech Stock - åƒæ•¸æ•æ„Ÿåº¦åˆ†æ")
    print(f"  çµ„åˆæ•¸: {len(HARD_STOP_GRID)} Ã— {len(CALLBACK_BASE_GRID)} Ã— {len(CALLBACK_HIGH_GRID)} = 75")
    print(f"  æ¨™çš„: {', '.join(TARGET_TICKERS)}")
    print("=" * 70)
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # è¼‰å…¥æ¨¡å‹
    print("\n[Step 1] è¼‰å…¥æ¨¡å‹èˆ‡æ•¸æ“š...")
    manifest = load_model_manifest(MODELS_PATH)
    if manifest is None:
        print("âŒ ç„¡æ³•è¼‰å…¥ manifest")
        return
    
    benchmark_df = load_or_update_local_csv(BENCHMARK)
    if benchmark_df is None:
        return
    
    # é å…ˆè¼‰å…¥æ‰€æœ‰æ•¸æ“šèˆ‡æ¨¡å‹
    models = {}
    features = {}
    
    for ticker in TARGET_TICKERS:
        print(f"  è¼‰å…¥ {ticker}...")
        model = load_ticker_model(ticker, manifest)
        if model is None:
            continue
        models[ticker] = model
        
        raw_df = load_or_update_local_csv(ticker)
        if raw_df is None:
            continue
        features[ticker] = calculate_features(raw_df, benchmark_df, ticker, use_cache=True)
    
    # åŸ·è¡Œç¶²æ ¼æœå°‹
    print("\n[Step 2] åŸ·è¡Œç¶²æ ¼æœå°‹...")
    all_results = []
    
    for ticker in TARGET_TICKERS:
        if ticker not in models:
            continue
        print(f"\nğŸ“ˆ {ticker}")
        results = run_grid_search(ticker, models[ticker], features[ticker])
        all_results.extend(results)
        print(f"  âœ… å®Œæˆ {len(results)} çµ„åƒæ•¸æ¸¬è©¦")
    
    # å½™ç¸½çµæœ
    results_df = pd.DataFrame(all_results)
    csv_path = os.path.join(OUTPUT_DIR, "sensitivity_analysis_results.csv")
    results_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… å®Œæ•´çµæœå·²å„²å­˜: {csv_path}")
    
    # ç¹ªè£½ç†±åœ–
    print("\n[Step 3] ç¹ªè£½è¦–è¦ºåŒ–åœ–è¡¨...")
    for ticker in ['NVDA', 'TSLA']:
        if ticker in models:
            plot_heatmap(results_df, ticker, OUTPUT_DIR)
            plot_3d_surface(results_df, ticker, OUTPUT_DIR)
    
    # åˆ†ææœ€ä½³åƒæ•¸
    print("\n[Step 4] åˆ†ææœ€ä½³åƒæ•¸...")
    compare_with_baseline(results_df, OUTPUT_DIR)
    
    print("\n" + "=" * 70)
    print("  âœ… æ•æ„Ÿåº¦åˆ†æå®Œæˆï¼")
    print(f"  ğŸ“ çµæœå„²å­˜æ–¼: {OUTPUT_DIR}/")
    print("=" * 70)


if __name__ == "__main__":
    main()
