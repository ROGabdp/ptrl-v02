#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
================================================================================
US Tech Stock Buy Agent - ä¿¡å¿ƒåº¦åˆ†å±¤åˆ†æ (Confidence Binning Analysis)
================================================================================
åˆ†æ Agent åœ¨ä¸åŒä¿¡å¿ƒåº¦å€é–“çš„æ±ºç­–æˆåŠŸç‡ï¼Œé©—è­‰æ¨¡å‹æ ¡æº–åº¦ã€‚

ä¿¡å¿ƒåº¦å€é–“:
- Tier 1: 90% ~ 100%
- Tier 2: 80% ~ 90%
- Tier 3: 70% ~ 80%
- Tier 4: 60% ~ 70%
- Tier 5: 50% ~ 60%

è¼¸å‡º:
- confidence_calibration_analysis.csv: è©³ç´°åˆ†å±¤çµ±è¨ˆ
- confidence_calibration_chart.png: åˆ†å±¤å°æ¯”åœ–è¡¨

ä½œè€…ï¼šPhil Liang (Generated by Gemini)
æ—¥æœŸï¼š2026-01-18
================================================================================
"""

import os
import sys
import json
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
from tqdm import tqdm

# Windows çµ‚ç«¯æ©Ÿ UTF-8 ç·¨ç¢¼è¨­å®š
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# è¨­å®šä¸­æ–‡å­—å‹
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# å°å…¥è¨“ç·´è…³æœ¬ä¸­çš„å‡½æ•¸
from train_us_tech_buy_agent import (
    load_or_update_local_csv,
    calculate_features,
    TICKERS, BENCHMARK, FEATURE_COLS, VAL_RANGE, MODELS_PATH
)

from stable_baselines3 import PPO


# =============================================================================
# å¸¸é‡å®šç¾©
# =============================================================================
VAL_START, VAL_END = VAL_RANGE
OUTPUT_DIR = "test_results"

# ä¿¡å¿ƒåº¦å€é–“å®šç¾©
CONFIDENCE_BINS = [
    ("90-100%", 0.90, 1.00),
    ("80-90%", 0.80, 0.90),
    ("70-80%", 0.70, 0.80),
    ("60-70%", 0.60, 0.70),
    ("50-60%", 0.50, 0.60),
]


# =============================================================================
# æ¨¡å‹è¼‰å…¥
# =============================================================================
def load_model_manifest(models_path: str) -> dict:
    """è¼‰å…¥ model_manifest.json"""
    manifest_path = os.path.join(models_path, "model_manifest.json")
    
    if not os.path.exists(manifest_path):
        print(f"âŒ æ‰¾ä¸åˆ° model_manifest.json: {manifest_path}")
        return None
    
    with open(manifest_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def load_ticker_model(ticker: str, manifest: dict) -> PPO:
    """è¼‰å…¥æŒ‡å®š Ticker çš„æ¨¡å‹"""
    if ticker not in manifest.get("tickers", {}):
        print(f"  âš ï¸ {ticker} ä¸åœ¨ manifest ä¸­")
        return None
    
    model_path = manifest["tickers"][ticker]["model_path"]
    
    if not os.path.exists(model_path):
        print(f"  âš ï¸ {ticker} æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")
        return None
    
    try:
        model = PPO.load(model_path, device="cpu")
        return model
    except Exception as e:
        print(f"  âŒ {ticker} æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None


# =============================================================================
# ä¿¡å¿ƒåº¦åˆ†æ
# =============================================================================
def get_action_confidence(model: PPO, obs: np.ndarray) -> tuple:
    """å–å¾—æ¨¡å‹çš„å‹•ä½œèˆ‡ä¿¡å¿ƒåº¦"""
    obs_tensor = torch.as_tensor(obs.reshape(1, -1), dtype=torch.float32)
    
    with torch.no_grad():
        distribution = model.policy.get_distribution(obs_tensor)
        probs = distribution.distribution.probs.numpy()[0]
        action, _ = model.predict(obs, deterministic=True)
        action = int(action)
        buy_confidence = float(probs[1])
    
    return action, buy_confidence


def analyze_ticker_confidence(ticker: str, model: PPO, features_df: pd.DataFrame) -> list:
    """
    åˆ†æå–®ä¸€è‚¡ç¥¨çš„ä¿¡å¿ƒåº¦åˆ†å±¤è¡¨ç¾
    
    Returns:
        list: å„ä¿¡å¿ƒåº¦å€é–“çš„çµ±è¨ˆçµæœ
    """
    # éæ¿¾æ¸¬è©¦æœŸé–“
    test_df = features_df[
        (features_df.index >= pd.Timestamp(VAL_START)) &
        (features_df.index <= pd.Timestamp(VAL_END))
    ].copy()
    
    test_df = test_df.dropna(subset=['Next_20d_Max'])
    
    if len(test_df) == 0:
        print(f"  âš ï¸ {ticker} ç„¡æœ‰æ•ˆè³‡æ–™")
        return []
    
    print(f"  æ¸¬è©¦æœŸé–“: {test_df.index[0].date()} ~ {test_df.index[-1].date()} ({len(test_df)} å¤©)")
    
    # æ”¶é›†æ‰€æœ‰æ±ºç­–
    decisions = []
    
    for idx in tqdm(range(len(test_df)), desc=f"  Analyzing {ticker}", leave=False):
        row = test_df.iloc[idx]
        obs = row[FEATURE_COLS].values.astype(np.float32)
        action, buy_confidence = get_action_confidence(model, obs)
        next_20d_max = row['Next_20d_Max']
        is_success = next_20d_max >= 0.10
        
        # åªæ”¶é›† Action=1 (BUY) çš„æ±ºç­–
        if action == 1:
            decisions.append({
                'confidence': buy_confidence,
                'next_20d_max': next_20d_max,
                'is_success': is_success
            })
    
    if len(decisions) == 0:
        print(f"  âš ï¸ {ticker} ç„¡è²·å…¥æ±ºç­–")
        return []
    
    decisions_df = pd.DataFrame(decisions)
    
    # åˆ†å±¤çµ±è¨ˆ
    bin_results = []
    
    for bin_name, bin_low, bin_high in CONFIDENCE_BINS:
        bin_data = decisions_df[
            (decisions_df['confidence'] >= bin_low) & 
            (decisions_df['confidence'] < bin_high)
        ]
        
        signal_count = len(bin_data)
        success_count = bin_data['is_success'].sum() if signal_count > 0 else 0
        precision = success_count / signal_count if signal_count > 0 else 0.0
        avg_max_return = bin_data['next_20d_max'].mean() if signal_count > 0 else 0.0
        
        bin_results.append({
            'ticker': ticker,
            'confidence_bin': bin_name,
            'bin_low': bin_low,
            'bin_high': bin_high,
            'signal_count': signal_count,
            'success_count': success_count,
            'precision': precision,
            'avg_max_return': avg_max_return
        })
    
    # é¡å¤–çµ±è¨ˆæ•´é«” >50% çš„æƒ…æ³
    total_signals = len(decisions_df)
    total_success = decisions_df['is_success'].sum()
    overall_precision = total_success / total_signals if total_signals > 0 else 0
    
    print(f"  ğŸ“Š ç¸½è²·å…¥ä¿¡è™Ÿ: {total_signals} | æˆåŠŸ: {total_success} | æ•´é«” Precision: {overall_precision:.1%}")
    
    return bin_results


# =============================================================================
# çµæœè¼¸å‡º
# =============================================================================
def save_calibration_csv(all_results: list, output_dir: str) -> pd.DataFrame:
    """å„²å­˜åˆ†å±¤åˆ†æ CSV"""
    if len(all_results) == 0:
        print("âš ï¸ ç„¡çµæœå¯å„²å­˜")
        return None
    
    df = pd.DataFrame(all_results)
    df['precision_pct'] = df['precision'].apply(lambda x: f"{x:.1%}")
    df['avg_return_pct'] = df['avg_max_return'].apply(lambda x: f"{x:.1%}")
    
    csv_path = os.path.join(output_dir, "confidence_calibration_analysis.csv")
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… åˆ†å±¤åˆ†æå·²å„²å­˜: {csv_path}")
    
    return df


def plot_calibration_chart(all_results: list, output_dir: str):
    """ç¹ªè£½ä¿¡å¿ƒåº¦æ ¡æº–åœ–è¡¨"""
    if len(all_results) == 0:
        print("âš ï¸ ç„¡çµæœå¯ç¹ªåœ–")
        return
    
    df = pd.DataFrame(all_results)
    tickers = df['ticker'].unique()
    n_tickers = len(tickers)
    
    # è¨­å®šå­åœ–å¸ƒå±€
    n_cols = 5
    n_rows = (n_tickers + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
    axes = axes.flatten() if n_rows > 1 else [axes] if n_tickers == 1 else axes.flatten()
    
    bin_labels = [b[0] for b in CONFIDENCE_BINS]
    x = np.arange(len(bin_labels))
    width = 0.6
    
    for i, ticker in enumerate(tickers):
        ax = axes[i]
        ticker_data = df[df['ticker'] == ticker].sort_values('bin_low', ascending=False)
        
        precisions = ticker_data['precision'].values * 100
        signal_counts = ticker_data['signal_count'].values
        
        # é•·æ¢åœ–ï¼šPrecision
        bars = ax.bar(x, precisions, width, color='#4CAF50', alpha=0.8, label='Precision')
        
        # æŠ˜ç·šåœ–ï¼šè¨Šè™Ÿæ¬¡æ•¸ (å³è»¸)
        ax2 = ax.twinx()
        line = ax2.plot(x, signal_counts, 'o-', color='#FF5722', linewidth=2, 
                        markersize=6, label='Signal Count')
        
        ax.set_ylabel('Precision (%)', fontsize=9)
        ax2.set_ylabel('Signal Count', fontsize=9, color='#FF5722')
        ax.set_xlabel('Confidence Bin', fontsize=9)
        ax.set_title(f'{ticker}', fontsize=11, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(bin_labels, fontsize=8, rotation=45)
        ax.set_ylim(0, 100)
        ax.grid(axis='y', alpha=0.3)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar, p, s in zip(bars, precisions, signal_counts):
            if s > 0:
                ax.annotate(f'{p:.0f}%', 
                            xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),
                            xytext=(0, 3), textcoords="offset points",
                            ha='center', va='bottom', fontsize=7)
    
    # éš±è—å¤šé¤˜çš„å­åœ–
    for i in range(n_tickers, len(axes)):
        axes[i].set_visible(False)
    
    fig.suptitle(f'Buy Agent ä¿¡å¿ƒåº¦æ ¡æº–åˆ†æ\næ¸¬è©¦æœŸé–“: {VAL_START} ~ {VAL_END}', 
                 fontsize=14, fontweight='bold')
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    
    chart_path = os.path.join(output_dir, "confidence_calibration_chart.png")
    plt.savefig(chart_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… æ ¡æº–åœ–è¡¨å·²å„²å­˜: {chart_path}")


def plot_aggregated_chart(all_results: list, output_dir: str):
    """ç¹ªè£½å½™ç¸½æ ¡æº–åœ–è¡¨"""
    if len(all_results) == 0:
        return
    
    df = pd.DataFrame(all_results)
    
    # æŒ‰ä¿¡å¿ƒåº¦å€é–“å½™ç¸½
    agg_df = df.groupby('confidence_bin').agg({
        'signal_count': 'sum',
        'success_count': 'sum',
        'avg_max_return': 'mean'
    }).reset_index()
    
    agg_df['precision'] = agg_df['success_count'] / agg_df['signal_count']
    
    # æŒ‰ bin_low æ’åº (éœ€è¦æå–)
    bin_order = {b[0]: b[1] for b in CONFIDENCE_BINS}
    agg_df['bin_order'] = agg_df['confidence_bin'].map(bin_order)
    agg_df = agg_df.sort_values('bin_order', ascending=False)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    x = np.arange(len(agg_df))
    width = 0.35
    
    bars1 = ax.bar(x - width/2, agg_df['precision'] * 100, width, 
                   label='Precision (%)', color='#4CAF50', alpha=0.8)
    bars2 = ax.bar(x + width/2, agg_df['avg_max_return'] * 100, width, 
                   label='Avg Max Return (%)', color='#2196F3', alpha=0.8)
    
    ax2 = ax.twinx()
    line = ax2.plot(x, agg_df['signal_count'], 's-', color='#FF5722', 
                    linewidth=2, markersize=8, label='Signal Count')
    
    ax.set_ylabel('ç™¾åˆ†æ¯” (%)', fontsize=11)
    ax2.set_ylabel('è¨Šè™Ÿæ¬¡æ•¸', fontsize=11, color='#FF5722')
    ax.set_xlabel('ä¿¡å¿ƒåº¦å€é–“', fontsize=11)
    ax.set_title(f'å…¨é«”è‚¡ç¥¨ä¿¡å¿ƒåº¦æ ¡æº–åˆ†æ (å½™ç¸½)\næ¸¬è©¦æœŸé–“: {VAL_START} ~ {VAL_END}', fontsize=13)
    ax.set_xticks(x)
    ax.set_xticklabels(agg_df['confidence_bin'].values, fontsize=10)
    ax.set_ylim(0, 80)
    ax.legend(loc='upper left')
    ax2.legend(loc='upper right')
    ax.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•¸å€¼æ¨™ç±¤
    for bar in bars1:
        h = bar.get_height()
        ax.annotate(f'{h:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, h),
                    xytext=(0, 3), textcoords="offset points",
                    ha='center', va='bottom', fontsize=9)
    
    for bar in bars2:
        h = bar.get_height()
        ax.annotate(f'{h:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, h),
                    xytext=(0, 3), textcoords="offset points",
                    ha='center', va='bottom', fontsize=9)
    
    plt.tight_layout()
    
    chart_path = os.path.join(output_dir, "confidence_calibration_aggregated.png")
    plt.savefig(chart_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… å½™ç¸½åœ–è¡¨å·²å„²å­˜: {chart_path}")


def print_calibration_summary(all_results: list):
    """å°å‡ºæ ¡æº–åˆ†ææ‘˜è¦"""
    if len(all_results) == 0:
        return
    
    df = pd.DataFrame(all_results)
    
    print("\n" + "=" * 100)
    print("ğŸ“Š ä¿¡å¿ƒåº¦åˆ†å±¤åˆ†ææ‘˜è¦")
    print(f"   æ¸¬è©¦æœŸé–“: {VAL_START} ~ {VAL_END}")
    print("=" * 100)
    
    # æŒ‰å€é–“å½™ç¸½
    print("\nã€å…¨é«”è‚¡ç¥¨å½™ç¸½ã€‘")
    print(f"{'ä¿¡å¿ƒåº¦å€é–“':>12} | {'è¨Šè™Ÿæ¬¡æ•¸':>8} | {'æˆåŠŸæ¬¡æ•¸':>8} | {'Precision':>10} | {'Avg Return':>10}")
    print("-" * 60)
    
    for bin_name, bin_low, bin_high in CONFIDENCE_BINS:
        bin_data = df[df['confidence_bin'] == bin_name]
        total_signals = bin_data['signal_count'].sum()
        total_success = bin_data['success_count'].sum()
        precision = total_success / total_signals if total_signals > 0 else 0
        avg_return = bin_data['avg_max_return'].mean() if len(bin_data) > 0 else 0
        
        print(f"{bin_name:>12} | {total_signals:>8} | {total_success:>8} | {precision:>9.1%} | {avg_return:>9.1%}")
    
    print("-" * 60)
    
    # åˆ†æçµè«–
    print("\nã€é—œéµç™¼ç¾ã€‘")
    
    # æ‰¾å‡ºé»ƒé‡‘é–€æª»
    for bin_name, bin_low, bin_high in CONFIDENCE_BINS:
        bin_data = df[df['confidence_bin'] == bin_name]
        if len(bin_data) > 0:
            avg_precision = (bin_data['success_count'].sum() / 
                           bin_data['signal_count'].sum() 
                           if bin_data['signal_count'].sum() > 0 else 0)
            if avg_precision >= 0.50:
                print(f"  âœ… é»ƒé‡‘é–€æª»: ä¿¡å¿ƒåº¦ â‰¥ {bin_low:.0%} æ™‚ï¼Œæ•´é«” Precision é” {avg_precision:.1%}")
                break
    
    # é«˜ä¿¡å¿ƒåº¦æ¨£æœ¬é‡
    high_conf_data = df[df['bin_low'] >= 0.80]
    high_conf_signals = high_conf_data['signal_count'].sum()
    total_signals = df['signal_count'].sum()
    high_conf_ratio = high_conf_signals / total_signals if total_signals > 0 else 0
    
    print(f"  ğŸ“ˆ é«˜ä¿¡å¿ƒåº¦ (â‰¥80%) æ¨£æœ¬é‡: {high_conf_signals} ({high_conf_ratio:.1%} of total)")
    
    if high_conf_ratio < 0.10:
        print(f"     âš ï¸ é«˜ä¿¡å¿ƒåº¦æ¨£æœ¬è¼ƒå°‘ï¼Œæ¨¡å‹å¯èƒ½éæ–¼ä¿å®ˆ")
    elif high_conf_ratio > 0.50:
        print(f"     âœ… é«˜ä¿¡å¿ƒåº¦æ¨£æœ¬å……è¶³ï¼Œæ¨¡å‹ä¿¡å¿ƒåº¦åˆ†ä½ˆè‰¯å¥½")
    
    print("=" * 100)


# =============================================================================
# ä¸»ç¨‹å¼
# =============================================================================
def main():
    print("=" * 70)
    print("  US Tech Stock Buy Agent - ä¿¡å¿ƒåº¦åˆ†å±¤åˆ†æ")
    print(f"  æ¸¬è©¦æœŸé–“: {VAL_START} ~ {VAL_END}")
    print("=" * 70)
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # è¼‰å…¥ manifest
    print("\n[Step 1] è¼‰å…¥ Model Manifest...")
    manifest = load_model_manifest(MODELS_PATH)
    if manifest is None:
        return
    
    # è¼‰å…¥åŸºæº–æŒ‡æ•¸
    print("\n[Step 2] è¼‰å…¥åŸºæº–æŒ‡æ•¸...")
    benchmark_df = load_or_update_local_csv(BENCHMARK)
    if benchmark_df is None:
        return
    
    # é€è‚¡åˆ†æ
    print("\n[Step 3] ä¿¡å¿ƒåº¦åˆ†å±¤åˆ†æ...")
    all_results = []
    
    for ticker in TICKERS:
        print(f"\nğŸ“ˆ {ticker}")
        print("-" * 40)
        
        model = load_ticker_model(ticker, manifest)
        if model is None:
            continue
        print(f"  âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        
        raw_df = load_or_update_local_csv(ticker)
        if raw_df is None:
            continue
        
        features_df = calculate_features(raw_df, benchmark_df, ticker, use_cache=True)
        bin_results = analyze_ticker_confidence(ticker, model, features_df)
        all_results.extend(bin_results)
    
    # è¼¸å‡ºçµæœ
    print("\n[Step 4] è¼¸å‡ºçµæœ...")
    
    print_calibration_summary(all_results)
    save_calibration_csv(all_results, OUTPUT_DIR)
    plot_calibration_chart(all_results, OUTPUT_DIR)
    plot_aggregated_chart(all_results, OUTPUT_DIR)
    
    print("\n" + "=" * 70)
    print("  âœ… åˆ†æå®Œæˆï¼")
    print(f"  ğŸ“ çµæœå„²å­˜æ–¼: {OUTPUT_DIR}/")
    print("=" * 70)


if __name__ == "__main__":
    main()
