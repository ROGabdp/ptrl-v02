# -*- coding: utf-8 -*-
"""
Hybrid Trading System for ^TWII (Taiwan Stock Index)
çµåˆ LSTM-SSAM åƒ¹æ ¼é æ¸¬èˆ‡ Pro Trader RL äº¤æ˜“æ±ºç­–

é–‹ç™¼ç­–ç•¥ï¼š
1. æ•¸æ“šæ“´å…… (Data Expansion)ï¼šå¼•å…¥åœ‹éš›æŒ‡æ•¸æ··åˆè¨“ç·´
2. ç‰¹å¾µèåˆ (Feature Fusion)ï¼šæ•´åˆ LSTM T+1/T+5 é æ¸¬èˆ‡ä¿¡å¿ƒåº¦
3. é·ç§»å­¸ç¿’ (Transfer Learning)ï¼šé€šç”¨ Agent â†’ ^TWII Fine-tuning

Phase 1: åŸºç¤è¨­å®šèˆ‡è³‡æ–™ä¸‹è¼‰ âœ…
Phase 2: ç‰¹å¾µå·¥ç¨‹èˆ‡ LSTM æ•´åˆ âœ…
Phase 3: æ··åˆæ•¸æ“šé è¨“ç·´ âœ…
Phase 4: ^TWII å¾®èª¿èˆ‡å›æ¸¬ âœ…
"""

import os
import sys
import pickle
import psutil
import shutil

# Windows çµ‚ç«¯æ©Ÿ UTF-8 ç·¨ç¢¼è¨­å®šï¼ˆè§£æ±º emoji é¡¯ç¤ºå•é¡Œï¼‰
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

import datetime
import numpy as np
import pandas as pd
import yfinance as yf
import ta
from ta.volatility import AverageTrueRange
from ta.momentum import RSIIndicator
from ta.volume import MFIIndicator
import gymnasium as gym
import matplotlib.pyplot as plt
import torch
from tqdm import tqdm
from gymnasium import spaces
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv
import glob
import multiprocessing
import warnings

# æŠ‘åˆ¶ TensorFlow è­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings('ignore')

# ä¸­æ–‡å­—å‹è¨­å®š
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False


# =============================================================================
# è¨­å®š
# =============================================================================
FEATURE_COLS = [
    'Norm_Close', 'Norm_Open', 'Norm_High', 'Norm_Low',
    'Norm_DC_Lower',
    'Norm_HA_Open', 'Norm_HA_High', 'Norm_HA_Low', 'Norm_HA_Close',
    'Norm_SuperTrend_1', 'Norm_SuperTrend_2',
    'Norm_RSI', 'Norm_MFI',
    'Norm_ATR_Change',
    'Norm_RS_Ratio',
    'RS_ROC_5', 'RS_ROC_10', 'RS_ROC_20', 'RS_ROC_60', 'RS_ROC_120',
    # [v6.0] ç§»é™¤ LSTM é æ¸¬ç‰¹å¾µ (T+1/T+5)
    # [v4.1] æ–°å¢ RL é¡¯æ€§ç‰¹å¾µ (Explicit Features)
    'Feat_MA20_Slope',   # çŸ­æœŸè¶¨å‹¢å‹•èƒ½
    'Feat_Trend_Gap',    # MA20 vs MA240 å¸‚å ´é«”åˆ¶
    'Feat_Bias_MA20',    # çŸ­æœŸä¹–é›¢
    'Feat_Dist_MA60',    # å­£ç·šæ”¯æ’è·é›¢
    'Feat_Dist_MA240',   # å¹´ç·šç”Ÿå‘½ç·šä½ç½®
    'Feat_Vol_Ratio',    # ç›¸å°æˆäº¤é‡çªæ³¢
    # [v4.2] æ–°å¢ KD èˆ‡ MACD ç‰¹å¾µ
    'Norm_K',            # Stochastic K(9,3) / 100
    'Norm_D',            # Stochastic D(9,3) / 100
    'Norm_DIF',          # MACD DIF(12,26) / Close
    'Norm_MACD',         # MACD Signal(9) / Close
    'Norm_OSC',          # MACD OSC (DIF - MACD) / Close
]

CACHE_DIR = "data/processed"
SPLIT_DATE = '2023-01-01'  # Fine-tuning / Backtest åˆ‡åˆ†é»


# =============================================================================
# 0. ç’°å¢ƒèˆ‡ GPU è¨­å®š
# =============================================================================
def setup_environment():
    """è¨­å®šåŸ·è¡Œç’°å¢ƒèˆ‡è·¯å¾‘"""
    # [v6.0] å¼·åˆ¶ä½¿ç”¨ CPU (å°å‹ MLP + å¤šç’°å¢ƒ PPO åœ¨ CPU æ›´å¿«)
    device = "cpu"
    print(f"[System] Device: {device} (forced for multi-env PPO)")

    PROJECT_PATH = os.getcwd()
    MODELS_PATH = os.path.join(PROJECT_PATH, 'models_hybrid')
    RESULTS_PATH = os.path.join(PROJECT_PATH, 'results_hybrid')
    DATA_PATH = os.path.join(PROJECT_PATH, 'data')
    PROCESSED_PATH = os.path.join(DATA_PATH, 'processed')

    for path in [MODELS_PATH, RESULTS_PATH, DATA_PATH, PROCESSED_PATH]:
        if not os.path.exists(path):
            os.makedirs(path)
            
    return PROJECT_PATH, MODELS_PATH, RESULTS_PATH, DATA_PATH, device


# =============================================================================
# 1. è³‡æ–™ä¸‹è¼‰
# =============================================================================
# =============================================================================
# 1. è³‡æ–™ä¸‹è¼‰
# =============================================================================
def _load_local_twii_data(start_date: str = "2000-01-01", end_date: str = None) -> pd.DataFrame:
    """
    è¼‰å…¥æœ¬åœ° TWII CSV è³‡æ–™ (å«è‡ªå‹•æ›´æ–°é‚è¼¯)
    
    Args:
        start_date: è³‡æ–™èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: è³‡æ–™çµæŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œè‹¥ç‚º None å‰‡å–åˆ°æœ€æ–°
    """
    from datetime import date
    import subprocess
    from pathlib import Path
    
    csv_file = Path(__file__).parent / "twii_data_from_2000_01_01.csv"
    
    if not csv_file.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆï¼š{csv_file}")
    
    # 1. è®€å– CSV
    df = pd.read_csv(csv_file)
    df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d')
    df = df.set_index('date')
    
    # 2. è‡ªå‹•æ›´æ–°æª¢æŸ¥
    today = date.today()
    last_date = df.index.max().date()
    
    if last_date < today:
        # æª¢æŸ¥ä»Šå¤©æ˜¯å¦ç‚ºäº¤æ˜“æ—¥ï¼ˆé€±ä¸€è‡³é€±äº”ï¼‰
        if today.weekday() < 5:  # 0-4 æ˜¯å¹³æ—¥
            print(f"[è³‡æ–™æ›´æ–°] TWII è³‡æ–™ ({last_date}) ä¸æ˜¯æœ€æ–°ï¼Œæ­£åœ¨å‘¼å« update_twii_data.py...")
            update_script = Path(__file__).parent / "update_twii_data.py"
            
            if update_script.exists():
                try:
                    result = subprocess.run(
                        [sys.executable, str(update_script)],
                        cwd=Path(__file__).parent,
                        capture_output=True,
                        text=True
                    )
                    if result.returncode == 0:
                        print(f"[è³‡æ–™æ›´æ–°] æ›´æ–°å®Œæˆï¼")
                        # é‡æ–°è®€å–æ›´æ–°å¾Œçš„æª”æ¡ˆ
                        df = pd.read_csv(csv_file)
                        df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d')
                        df = df.set_index('date')
                    else:
                        print(f"[è­¦å‘Š] æ›´æ–°å¤±æ•—ï¼š{result.stderr}")
                except Exception as e:
                    print(f"[è­¦å‘Š] åŸ·è¡Œæ›´æ–°è…³æœ¬éŒ¯èª¤ï¼š{e}")
            else:
                print(f"[è­¦å‘Š] æ‰¾ä¸åˆ°æ›´æ–°è…³æœ¬ï¼š{update_script}")
    
    # 3. æ¬„ä½é‡æ–°å‘½åèˆ‡éæ¿¾
    df = df.rename(columns={
        'open': 'Open',
        'high': 'High',
        'low': 'Low',
        'close': 'Close',
        'volume': 'Volume'  # å–®ä½ï¼šå„„å…ƒ
    })
    
    # ç¯©é¸æ—¥æœŸç¯„åœ
    start_dt = pd.Timestamp(start_date)
    df = df[df.index >= start_dt]
    
    # [æ–°å¢] è‹¥æŒ‡å®š end_dateï¼Œå‰‡éæ¿¾æ‰ä¹‹å¾Œçš„è³‡æ–™
    if end_date is not None:
        end_dt = pd.Timestamp(end_date)
        df = df[df.index < end_dt]
        print(f"  âœ… ^TWII (Local, æˆªæ­¢ {end_date}): {len(df)} ç­† ({df.index[0].date()} ~ {df.index[-1].date()})")
    else:
        print(f"  âœ… ^TWII (Local): {len(df)} ç­† ({df.index[0].date()} ~ {df.index[-1].date()})")
    
    return df


def fetch_index_data(data_path, start_date="2000-01-01", end_date=None):
    """
    ä¸‹è¼‰å¸‚å ´æŒ‡æ•¸è³‡æ–™ (TWII ä½¿ç”¨æœ¬åœ° CSV)
    
    Args:
        data_path: è³‡æ–™å„²å­˜è·¯å¾‘
        start_date: è³‡æ–™èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: è³‡æ–™çµæŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œè‹¥ç‚º None å‰‡å–åˆ°æœ€æ–°
                  [é‡è¦] é è¨“ç·´æ™‚æ‡‰å‚³å…¥ SPLIT_DATE ä»¥é¿å…è³‡æ–™æ´©æ¼
    """
    # TWII ä»¥å¤–çš„åœ‹éš›æŒ‡æ•¸
    foreign_indices = ["^GSPC", "^IXIC", "^SOX", "^DJI"]
    
    print(f"=" * 60)
    print(f"ğŸ“¥ ä¸‹è¼‰/è¼‰å…¥ å¸‚å ´æŒ‡æ•¸è³‡æ–™")
    if end_date:
        print(f"   (è³‡æ–™ç¯„åœ: {start_date} ~ {end_date}ï¼Œé˜²æ­¢è³‡æ–™æ´©æ¼)")
    print(f"=" * 60)
    
    clean_data = {}
    
    # 1. è¼‰å…¥æœ¬åœ° TWII (å‚³å…¥ end_date)
    try:
        clean_data["^TWII"] = _load_local_twii_data(start_date, end_date)
    except Exception as e:
        print(f"  âŒ ^TWII Loading Failed: {e}")
        
    # 2. ä¸‹è¼‰åœ‹éš›æŒ‡æ•¸ (è‹¥æœ‰ end_dateï¼Œå‰‡é™åˆ¶ä¸‹è¼‰ç¯„åœ)
    if foreign_indices:
        print(f"[ä¸‹è¼‰] æ­£åœ¨ç²å–åœ‹éš›æŒ‡æ•¸: {', '.join(foreign_indices)}...")
        download_end = end_date if end_date else None
        data = yf.download(foreign_indices, start=start_date, end=download_end,
                           group_by='ticker', auto_adjust=True, threads=True, progress=False)
        
        for t in foreign_indices:
            try:
                # è™•ç† MultiIndex æˆ– Single Index
                if isinstance(data.columns, pd.MultiIndex):
                     if t in data.columns.levels[0]:
                        df = data[t].copy()
                else:
                    # å¦‚æœåªæœ‰ä¸€å€‹ tickerï¼Œyf å¯èƒ½ä¸æœƒå›å‚³ MultiIndexï¼Œéœ€æª¢æŸ¥
                    # ä½†é€™è£¡æˆ‘å€‘å‚³å…¥äº† listï¼Œé€šå¸¸æœƒæ˜¯ MultiIndex
                    # è‹¥ç‚ºé˜²è¬ä¸€ï¼Œå‡è¨­ data å°±æ˜¯è©² ticker çš„ df (ä¸éé€™è£¡æœ‰å¤šå€‹ ticker)
                    continue

                if isinstance(df.columns, pd.MultiIndex):
                    df.columns = df.columns.get_level_values(0)
                
                df = df.dropna()
                if len(df) > 250:
                    clean_data[t] = df
                    print(f"  âœ… {t}: {len(df)} ç­†")
            except Exception as e:
                print(f"  âš ï¸ {t}: Failed - {e}")
    
    return clean_data


# =============================================================================
# 2. LSTM æ¨¡å‹è¼‰å…¥èˆ‡æ¨è«–
# =============================================================================
_LSTM_MODELS = {
    'model_1d': None, 'scaler_feat_1d': None, 'scaler_tgt_1d': None, 'meta_1d': None,
    'model_5d': None, 'scaler_feat_5d': None, 'scaler_tgt_5d': None, 'meta_5d': None,
    'model_20d': None, 'scaler_feat_20d': None, 'scaler_tgt_20d': None, 'meta_20d': None,
    'loaded': False
}

def load_best_lstm_models(target_date=None):
    """è¼‰å…¥ LSTM æ¨¡å‹"""
    global _LSTM_MODELS
    if _LSTM_MODELS['loaded']:
        # If loaded, check if we need to reload for a different date? 
        # For simplicity, if target_date is different, we should probably reload, 
        # but the simple check might be enough if we restart script.
        # But to be safe for this script usage, let's allow reload if forced or just assume script starts fresh.
        # However, checking against loaded metadata might be complex here.
        # Let's assume for this specific task, we call it once. 
        pass
        # (If we wanted to be robust, we'd check if loaded models match target_date criteria)
    
    print("\n[System] Loading LSTM Models...")
    try:
        import twii_model_registry_multivariate as lstm_1d_module
        import twii_model_registry_5d as lstm_5d_module
        import twii_model_registry_20d as lstm_20d_module
        from datetime import date
        
        use_date = target_date if target_date else date.today()
        print(f"[System] Selecting models available before: {use_date}")
        
        # 1. T+1 Model
        meta_1d = lstm_1d_module.select_best_model(use_date)
        if meta_1d is None:
            return False
        model_1d, scaler_feat_1d, scaler_tgt_1d, _ = lstm_1d_module.load_artifacts(
            meta_1d['train_start'], meta_1d['train_end'])
        print(f"  âœ… T+1 Model: {meta_1d['train_start']} ~ {meta_1d['train_end']}")
        
        # 2. T+5 Model
        meta_5d = lstm_5d_module.select_best_model(use_date)
        if meta_5d is None:
            return False
        model_5d, scaler_feat_5d, scaler_tgt_5d, _ = lstm_5d_module.load_artifacts(
            meta_5d['train_start'], meta_5d['train_end'])
        print(f"  âœ… T+5 Model: {meta_5d['train_start']} ~ {meta_5d['train_end']}")

        # 3. T+20 Model
        meta_20d = lstm_20d_module.select_best_model(use_date)
        if meta_20d is None:
            print("[Warning] No T+20 Model found. RL features will be incomplete.")
            return False
        model_20d, scaler_feat_20d, scaler_tgt_20d, _ = lstm_20d_module.load_artifacts(
            meta_20d['train_start'], meta_20d['train_end'])
        print(f"  âœ… T+20 Model: {meta_20d['train_start']} ~ {meta_20d['train_end']}")
        
        _LSTM_MODELS.update({
            'model_1d': model_1d, 'scaler_feat_1d': scaler_feat_1d,
            'scaler_tgt_1d': scaler_tgt_1d, 'meta_1d': meta_1d,
            'model_5d': model_5d, 'scaler_feat_5d': scaler_feat_5d,
            'scaler_tgt_5d': scaler_tgt_5d, 'meta_5d': meta_5d,
            'model_20d': model_20d, 'scaler_feat_20d': scaler_feat_20d,
            'scaler_tgt_20d': scaler_tgt_20d, 'meta_20d': meta_20d,
            'loaded': True
        })
        return True
    except Exception as e:
        print(f"[Error] Failed to load LSTM models: {e}")
        return False


def add_lstm_features(df: pd.DataFrame, ticker: str = "Unknown") -> pd.DataFrame:
    """
    [v6.0] LSTM ç‰¹å¾µå·²å¾ RL è¨“ç·´ä¸­ç§»é™¤
    
    æ­¤å‡½å¼ä¿ç•™ä»¥ç¶­æŒå‘ä¸‹ç›¸å®¹æ€§ï¼Œä½†ä¸å†åŸ·è¡Œä»»ä½• LSTM è¨ˆç®—ã€‚
    LSTM ç‰¹å¾µæ¬„ä½ä»æœƒè¢«åˆå§‹åŒ–ç‚ºé è¨­å€¼ï¼Œä»¥é¿å…å…¶ä»–è…³æœ¬å ±éŒ¯ã€‚
    """
    # åˆå§‹åŒ–æ¬„ä½ï¼ˆé è¨­å€¼ï¼Œä¾›å‘ä¸‹ç›¸å®¹ï¼‰
    for col in ['LSTM_Pred_1d', 'LSTM_Conf_1d', 'LSTM_Pred_5d', 'LSTM_Conf_5d', 'LSTM_Pred_20d', 'LSTM_Conf_20d']:
        if col not in df.columns:
            df[col] = 0.5 if 'Conf' in col else 0.0
    
    # [v6.0] ä¸å†åŸ·è¡Œ LSTM æ¨¡å‹æ¨è«–
    return df


def _add_lstm_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """æ–°å¢ LSTM æŠ€è¡“æŒ‡æ¨™"""
    df = df.copy()
    df['Volume_Log'] = np.log1p(df['Volume'])
    low_min = df['Low'].rolling(9).min()
    high_max = df['High'].rolling(9).max()
    df['K'] = ((df['Close'] - low_min) / (high_max - low_min) * 100).rolling(3).mean()
    df['D'] = df['K'].rolling(3).mean()
    ema_fast = df['Close'].ewm(span=12, adjust=False).mean()
    ema_slow = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD_Hist'] = (ema_fast - ema_slow) - (ema_fast - ema_slow).ewm(span=9, adjust=False).mean()
    if 'Adj Close' not in df.columns:
        df['Adj Close'] = df['Close']
    return df


# =============================================================================
# 3. æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µå·¥ç¨‹
# =============================================================================
def calculate_heikin_ashi(df):
    ha_close = (df['Open'] + df['High'] + df['Low'] + df['Close']) / 4
    ha_open = [df['Open'].iloc[0]]
    for i in range(1, len(df)):
        ha_open.append((ha_open[-1] + ha_close.iloc[i-1]) / 2)
    ha_open = pd.Series(ha_open, index=df.index)
    return pd.DataFrame({
        'HA_open': ha_open, 'HA_high': pd.concat([df['High'], ha_open, ha_close], axis=1).max(axis=1),
        'HA_low': pd.concat([df['Low'], ha_open, ha_close], axis=1).min(axis=1), 'HA_close': ha_close
    })


def calculate_supertrend(df, length=14, multiplier=3.0):
    atr = AverageTrueRange(df['High'], df['Low'], df['Close'], window=length).average_true_range().fillna(method='bfill')
    hl2 = (df['High'] + df['Low']) / 2
    basic_upper, basic_lower = hl2 + multiplier * atr, hl2 - multiplier * atr
    final_upper, final_lower = basic_upper.copy(), basic_lower.copy()
    trend = np.zeros(len(df))
    for i in range(1, len(df)):
        final_upper.iloc[i] = basic_upper.iloc[i] if basic_upper.iloc[i] < final_upper.iloc[i-1] or df['Close'].iloc[i-1] > final_upper.iloc[i-1] else final_upper.iloc[i-1]
        final_lower.iloc[i] = basic_lower.iloc[i] if basic_lower.iloc[i] > final_lower.iloc[i-1] or df['Close'].iloc[i-1] < final_lower.iloc[i-1] else final_lower.iloc[i-1]
        trend[i] = 1 if df['Close'].iloc[i] > final_upper.iloc[i-1] else (-1 if df['Close'].iloc[i] < final_lower.iloc[i-1] else trend[i-1])
    return pd.DataFrame({'SUPERT_': np.where(trend == 1, final_lower, final_upper)}, index=df.index)


def calculate_features(df_in: pd.DataFrame, benchmark_df: pd.DataFrame, 
                       ticker: str = "Unknown", use_cache: bool = True) -> pd.DataFrame:
    """è¨ˆç®—å®Œæ•´ç‰¹å¾µ"""
    cache_path = os.path.join(CACHE_DIR, f"{ticker.replace('^', '_').replace('.', '_')}_features.pkl")
    
    if use_cache and os.path.exists(cache_path):
        print(f"[Cache] Loading features for {ticker}...")
        try:
            with open(cache_path, 'rb') as f:
                return pickle.load(f)
        except:
            pass
    
    print(f"[Compute] Generating features for {ticker}...")
    df = df_in.copy()
    
    df['DC_Upper'] = df['High'].rolling(20).max().shift(1).fillna(method='bfill')
    df['DC_Lower'] = df['Low'].rolling(20).min().shift(1).fillna(method='bfill')
    df['DC_Upper_10'] = df['High'].rolling(10).max().shift(1).fillna(method='bfill')
    df['ATR'] = AverageTrueRange(df['High'], df['Low'], df['Close'], window=10).average_true_range()
    df['RSI'] = RSIIndicator(df['Close'], window=14).rsi()
    try:
        df['MFI'] = MFIIndicator(df['High'], df['Low'], df['Close'], df['Volume'], window=14).money_flow_index()
    except:
        df['MFI'] = 50.0
    
    ha = calculate_heikin_ashi(df)
    df['HA_Open'], df['HA_High'], df['HA_Low'], df['HA_Close'] = ha['HA_open'], ha['HA_high'], ha['HA_low'], ha['HA_close']
    df['SuperTrend_1'] = calculate_supertrend(df, 14, 2.0).iloc[:, 0]
    df['SuperTrend_2'] = calculate_supertrend(df, 21, 1.0).iloc[:, 0]
    
    base_price = df['DC_Upper'].replace(0, np.nan).fillna(method='bfill')
    for col in ['Close', 'Open', 'High', 'Low', 'DC_Lower', 'HA_Open', 'HA_High', 'HA_Low', 'HA_Close', 'SuperTrend_1', 'SuperTrend_2']:
        df[f'Norm_{col}'] = df[col] / base_price
    df['Norm_RSI'], df['Norm_MFI'] = df['RSI'] / 100.0, df['MFI'] / 100.0
    df['Norm_ATR_Change'] = (df['ATR'] / df['ATR'].shift(1)).fillna(1.0)
    
    # -------------------------------------------------------------------------
    # [v4.1] æ–°å¢ RL é¡¯æ€§ç‰¹å¾µ (Explicit Features)
    # -------------------------------------------------------------------------
    # 1. åŸºç¤å‡ç·šè¨ˆç®—
    # ç¢ºä¿æˆäº¤é‡åˆ†æ¯ä¸ç‚º 0
    df['MA20'] = df['Close'].rolling(20).mean()
    df['MA60'] = df['Close'].rolling(60).mean()
    df['MA120'] = df['Close'].rolling(120).mean()
    df['MA240'] = df['Close'].rolling(240).mean()
    df['MA_Vol_20'] = df['Volume'].rolling(20).mean()
    
    # 2. ç‰¹å¾µå…¬å¼å¯¦ä½œ
    # (1) MA20 çŸ­æœŸè¶¨å‹¢å‹•èƒ½: (MA20_t / MA20_t-1) - 1
    df['Feat_MA20_Slope'] = (df['MA20'] / df['MA20'].shift(1) - 1).fillna(0)
    
    # (2) MA20 vs MA240 å¸‚å ´é«”åˆ¶: (MA20 - MA240) / MA240
    df['Feat_Trend_Gap'] = ((df['MA20'] - df['MA240']) / df['MA240']).fillna(0)
    
    # (3) MA20 çŸ­æœŸä¹–é›¢: (Close - MA20) / MA20
    df['Feat_Bias_MA20'] = ((df['Close'] - df['MA20']) / df['MA20']).fillna(0)
    
    # (4) MA60 å­£ç·šæ”¯æ’è·é›¢: (Close - MA60) / MA60
    df['Feat_Dist_MA60'] = ((df['Close'] - df['MA60']) / df['MA60']).fillna(0)
    
    # (5) MA240 å¹´ç·šç”Ÿå‘½ç·šä½ç½®: (Close - MA240) / MA240
    df['Feat_Dist_MA240'] = ((df['Close'] - df['MA240']) / df['MA240']).fillna(0)
    
    # (6) ç›¸å°æˆäº¤é‡çªæ³¢: Volume / MA_Vol_20
    # åŠ  1e-8 é˜²æ­¢é™¤ä»¥é›¶
    df['Feat_Vol_Ratio'] = (df['Volume'] / (df['MA_Vol_20'] + 1e-8)).fillna(0)
    
    # -------------------------------------------------------------------------
    # [v4.2] æ–°å¢ KD èˆ‡ MACD ç‰¹å¾µ
    # -------------------------------------------------------------------------
    # 1. Stochastic KD (9, 3)
    low_min_9 = df['Low'].rolling(9).min()
    high_max_9 = df['High'].rolling(9).max()
    rsv = ((df['Close'] - low_min_9) / (high_max_9 - low_min_9 + 1e-9)) * 100
    df['K_raw'] = rsv.rolling(3).mean()  # K(9,3)
    df['D_raw'] = df['K_raw'].rolling(3).mean()  # D(9,3)
    df['Norm_K'] = (df['K_raw'] / 100.0).fillna(0.5)
    df['Norm_D'] = (df['D_raw'] / 100.0).fillna(0.5)
    
    # 2. MACD (12, 26, 9)
    ema_12 = df['Close'].ewm(span=12, adjust=False).mean()
    ema_26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['DIF'] = ema_12 - ema_26  # DIF (å¿«ç·š - æ…¢ç·š)
    df['MACD_Signal'] = df['DIF'].ewm(span=9, adjust=False).mean()  # MACD Signal
    df['OSC'] = df['DIF'] - df['MACD_Signal']  # OSC (æŸ±ç‹€åœ–)
    
    # æ­£è¦åŒ–ï¼šé™¤ä»¥æ”¶ç›¤åƒ¹ (è½‰ç‚ºç™¾åˆ†æ¯”æ¦‚å¿µ)
    df['Norm_DIF'] = (df['DIF'] / df['Close']).fillna(0)
    df['Norm_MACD'] = (df['MACD_Signal'] / df['Close']).fillna(0)
    df['Norm_OSC'] = (df['OSC'] / df['Close']).fillna(0)
    
    # ç§»é™¤è¨ˆç®—éç¨‹ä¸­ç”¢ç”Ÿçš„æš«æ™‚æ¬„ä½ (ä¿ç•™ MA ä»¥ä¾¿ debug ä¹Ÿå¯ä»¥ï¼Œä½†é€™è£¡å…ˆä¿æŒä¹¾æ·¨)
    # df = df.drop(columns=['MA20', 'MA60', 'MA240', 'MA_Vol_20']) 
    
    # é‡è¦ï¼šç§»é™¤å› ç‚º MA240 é€ æˆçš„å‰ç«¯ç©ºå€¼
    df = df.dropna(subset=['MA240']) 
    
    if benchmark_df is not None:
        bench_close = benchmark_df['Close'].reindex(df.index).fillna(method='ffill')
        df['RS_Raw'] = df['Close'] / bench_close
        rs_min, rs_max = df['RS_Raw'].rolling(250).min(), df['RS_Raw'].rolling(250).max()
        df['Norm_RS_Ratio'] = ((df['RS_Raw'] - rs_min) / ((rs_max - rs_min).replace(0, np.nan).fillna(1.0) + 1e-9)).fillna(0.5)
        for period in [5, 10, 20, 60, 120]:
            df[f'RS_ROC_{period}'] = df['RS_Raw'].pct_change(period).fillna(0)
    else:
        df['Norm_RS_Ratio'] = 0.5
        for period in [5, 10, 20, 60, 120]:
            df[f'RS_ROC_{period}'] = 0.0
    
    df = add_lstm_features(df, ticker)
    df['Signal_Buy_Filter'] = df['High'] > df['DC_Upper_10']
    # è¨ˆç®—æœªä¾† N å¤©å…§çš„æœ€é«˜åƒ¹å ±é…¬ç‡ï¼ˆæ­£ç¢ºå…¬å¼ï¼‰
    # ç›®æ¨™ï¼šè¨ˆç®— T+1 åˆ° T+N é€™ N å¤©çš„æœ€é«˜åƒ¹
    # å…¬å¼ï¼šå…ˆ shift(-1) æ’é™¤ç•¶å¤©ï¼Œåè½‰å¾Œ rolling å–æœ€å¤§å€¼ï¼Œå†åè½‰å›ä¾†
    df['Next_20d_Max'] = df['High'].shift(-1).iloc[::-1].rolling(20, min_periods=20).max().iloc[::-1] / df['Close'] - 1
    df['Next_120d_Max'] = df['High'].shift(-1).iloc[::-1].rolling(120, min_periods=120).max().iloc[::-1] / df['Close'] - 1
    df = df.dropna(subset=[c for c in df.columns if c not in ['Next_20d_Max', 'Next_120d_Max']])
    
    if use_cache:
        try:
            os.makedirs(os.path.dirname(cache_path), exist_ok=True)
            with open(cache_path, 'wb') as f:
                pickle.dump(df, f)
        except:
            pass
    
    return df


# =============================================================================
# 4. RL ç’°å¢ƒå®šç¾©
# =============================================================================
class BuyEnvHybrid(gym.Env):
    """Buy RL Environment with class balancing"""
    def __init__(self, data_dict, is_training=True):
        super().__init__()
        self.samples, self.pos_samples, self.neg_samples = [], [], []
        
        for t, df in data_dict.items():
            df = df.dropna(subset=['Next_120d_Max'])  # æ”¹ç”¨ 120 å¤©ç›®æ¨™
            signals = df  # ç§»é™¤å”å…¶å®‰é€šé“é™åˆ¶ï¼Œæ‰€æœ‰æ—¥æœŸéƒ½å¯è²·å…¥
            if len(signals) > 0:
                states = signals[FEATURE_COLS].values.astype(np.float32)
                future_rets = signals['Next_120d_Max'].values.astype(np.float32)  # æ”¹ç”¨ 120 å¤©æœ€é«˜å ±é…¬
                for i in range(len(signals)):
                    sample = (states[i], future_rets[i])
                    self.samples.append(sample)
                    (self.pos_samples if future_rets[i] >= 0.10 else self.neg_samples).append(sample)
        
        print(f"[BuyEnv] Total samples: {len(self.samples)} | Pos samples (>10%): {len(self.pos_samples)} | Neg samples: {len(self.neg_samples)}")
        if len(self.pos_samples) == 0:
            print("[BuyEnv Warning] No positive samples found! Reward might be stuck at 0 if agent buys.")
        
        self.action_space = spaces.Discrete(2)
        self.observation_space = spaces.Box(-np.inf, np.inf, shape=(len(FEATURE_COLS),), dtype=np.float32)
        self.is_training = is_training
        self.idx, self.current_sample = 0, None
    
    def reset(self, seed=None, options=None):
        # [v6.02] è¨“ç·´æ™‚ä½¿ç”¨é¡åˆ¥å¹³è¡¡ 50/50ï¼Œé©—è­‰æ™‚ä½¿ç”¨çœŸå¯¦åˆ†ä½ˆ
        if self.is_training:
            # è¨“ç·´æ¨¡å¼ï¼š50/50 é¡åˆ¥å¹³è¡¡
            if np.random.rand() < 0.5 and self.pos_samples:
                self.current_sample = self.pos_samples[np.random.randint(len(self.pos_samples))]
            elif self.neg_samples:
                self.current_sample = self.neg_samples[np.random.randint(len(self.neg_samples))]
            else:
                self.current_sample = self.samples[np.random.randint(len(self.samples))]
        else:
            # é©—è­‰æ¨¡å¼ï¼šä½¿ç”¨çœŸå¯¦åˆ†ä½ˆ (åæ˜ å¯¦éš›å¸‚å ´æ©Ÿæœƒæ¯”ä¾‹)
            self.current_sample = self.samples[np.random.randint(len(self.samples))]
        return self.current_sample[0], {}
    
    def step(self, action):
        _, max_ret = self.current_sample
        is_success = max_ret >= 0.10  # æœªä¾† 120 å¤©æœ€å¤§æ¼²å¹… >= 10%
        
        if action == 1:  # é¸æ“‡è²·å…¥
            if is_success:
                reward = 2.0  # è²·å°ï¼šé«˜çå‹µ
            else:
                reward = -0.5  # è²·éŒ¯ï¼šè¼•å¾®æ‡²ç½°
        else:  # é¸æ“‡ä¸è²·
            if is_success:
                reward = -1.0  # éŒ¯éå¥½æ©Ÿæœƒï¼šæ‡²ç½°
            else:
                reward = 0.5   # æ­£ç¢ºè¿´é¿ï¼šè¼ƒä½çå‹µ
        
        return self.current_sample[0], reward, True, False, {}


class BuyEnvHybridV5(gym.Env):
    """Buy RL Environment V5 - å°ç¨±çå‹µçµæ§‹
    
    çå‹µè¨­è¨ˆï¼š
    - è²·å° (action=1, æ¼²å¹…â‰¥10%): +1.0
    - è²·éŒ¯ (action=1, æ¼²å¹…<10%): 0.0
    - éŒ¯éå¥½æ©Ÿæœƒ (action=0, æ¼²å¹…â‰¥10%): 0.0
    - æ­£ç¢ºè¿´é¿ (action=0, æ¼²å¹…<10%): +1.0
    """
    def __init__(self, data_dict, is_training=True):
        super().__init__()
        self.samples, self.pos_samples, self.neg_samples = [], [], []
        
        for t, df in data_dict.items():
            df = df.dropna(subset=['Next_120d_Max'])
            signals = df  # ç„¡å”å…¶å®‰é€šé“é™åˆ¶
            if len(signals) > 0:
                states = signals[FEATURE_COLS].values.astype(np.float32)
                future_rets = signals['Next_120d_Max'].values.astype(np.float32)
                for i in range(len(signals)):
                    sample = (states[i], future_rets[i])
                    self.samples.append(sample)
                    (self.pos_samples if future_rets[i] >= 0.10 else self.neg_samples).append(sample)
        
        print(f"[BuyEnvV5] Total samples: {len(self.samples)} | Pos (â‰¥10%): {len(self.pos_samples)} | Neg: {len(self.neg_samples)}")
        
        self.action_space = spaces.Discrete(2)
        self.observation_space = spaces.Box(-np.inf, np.inf, shape=(len(FEATURE_COLS),), dtype=np.float32)
        self.is_training = is_training
        self.idx, self.current_sample = 0, None
    
    def reset(self, seed=None, options=None):
        # [v6.02] è¨“ç·´æ™‚ä½¿ç”¨é¡åˆ¥å¹³è¡¡ 50/50ï¼Œé©—è­‰æ™‚ä½¿ç”¨çœŸå¯¦åˆ†ä½ˆ
        if self.is_training:
            # è¨“ç·´æ¨¡å¼ï¼š50/50 é¡åˆ¥å¹³è¡¡
            if np.random.rand() < 0.5 and self.pos_samples:
                self.current_sample = self.pos_samples[np.random.randint(len(self.pos_samples))]
            elif self.neg_samples:
                self.current_sample = self.neg_samples[np.random.randint(len(self.neg_samples))]
            else:
                self.current_sample = self.samples[np.random.randint(len(self.samples))]
        else:
            # é©—è­‰æ¨¡å¼ï¼šä½¿ç”¨çœŸå¯¦åˆ†ä½ˆ (åæ˜ å¯¦éš›å¸‚å ´æ©Ÿæœƒæ¯”ä¾‹)
            self.current_sample = self.samples[np.random.randint(len(self.samples))]
        return self.current_sample[0], {}
    
    def step(self, action):
        _, max_ret = self.current_sample
        is_success = max_ret >= 0.10  # æœªä¾† 120 å¤©æœ€å¤§æ¼²å¹… >= 10%
        
        # V5 å°ç¨±çå‹µçµæ§‹
        if action == 1:  # é¸æ“‡è²·å…¥
            reward = 1.0 if is_success else 0.0
        else:  # é¸æ“‡ä¸è²·
            reward = 0.0 if is_success else 1.0
        
        return self.current_sample[0], reward, True, False, {}

class SellEnvHybrid(gym.Env):
    """Sell RL Environment (v6.0 - Fixed Reward Hacking)
    
    ä¿®æ­£é‡é»:
    1. éš¨æ©ŸåŒ– Episode é•·åº¦ (60~250 å¤©)ï¼Œé¿å… Agent å­¸æœƒã€Œæ­»å®ˆåˆ°ç¬¬ N å¤©ã€
    2. è§£è€¦çå‹µè¦–çª—ï¼šç„¡è«–ä½•æ™‚çµç®—ï¼Œéƒ½å¾€å¾Œçœ‹å›ºå®š 60 å¤©ä¾†è¨ˆç®—éŒ¯å¤±çå‹µ
    3. è³‡æ–™åˆ‡ç‰‡æ“´å¤§åˆ° 310 å¤©ï¼Œç¢ºä¿æœ‰è¶³å¤ çš„æœªä¾†æ•¸æ“šä¾›çå‹µè¨ˆç®—
    """
    
    # Episode / Reward åƒæ•¸
    MIN_EPISODE_LENGTH = 60
    MAX_EPISODE_LENGTH = 250
    REWARD_LOOKAHEAD = 60  # çµç®—æ™‚å¾€å¾Œå·çœ‹çš„å¤©æ•¸
    DATA_BUFFER = MAX_EPISODE_LENGTH + REWARD_LOOKAHEAD  # 310 å¤©
    
    def __init__(self, data_dict):
        super().__init__()
        self.episodes = []
        
        for t, df in data_dict.items():
            buy_indices = np.where(df['Signal_Buy_Filter'])[0]
            feature_data = df[FEATURE_COLS].values.astype(np.float32)
            close_prices = df['Close'].values.astype(np.float32)
            
            for idx in buy_indices:
                # ç¢ºä¿æœ‰è¶³å¤ çš„æ•¸æ“šä¾› Episode + Lookahead
                if idx + self.DATA_BUFFER < len(df):
                    episode_prices = close_prices[idx:idx + self.DATA_BUFFER]
                    self.episodes.append({
                        'features': feature_data[idx:idx + self.DATA_BUFFER],
                        'returns': episode_prices / episode_prices[0]
                    })
        
        self.action_space = spaces.Discrete(2)
        self.observation_space = spaces.Box(-np.inf, np.inf, shape=(len(FEATURE_COLS) + 1,), dtype=np.float32)
        
        # æœƒåœ¨ reset æ™‚éš¨æ©Ÿæ±ºå®š
        self.max_steps = self.MAX_EPISODE_LENGTH
        self.current_episode = None
        self.day = 0
    
    def reset(self, seed=None, options=None):
        self.current_episode = self.episodes[np.random.randint(len(self.episodes))]
        self.day = 0
        # ğŸ”€ éš¨æ©ŸåŒ–æœ¬å›åˆçš„æœ€å¤§æ­¥æ•¸
        self.max_steps = np.random.randint(self.MIN_EPISODE_LENGTH, self.MAX_EPISODE_LENGTH + 1)
        return np.concatenate([self.current_episode['features'][0], [1.0]]).astype(np.float32), {}
    
    def step(self, action):
        current_return = self.current_episode['returns'][self.day]
        
        # å¼·åˆ¶çµç®—æ¢ä»¶ï¼šAgent é¸æ“‡è³£å‡º OR é”åˆ°æœ¬å›åˆéš¨æ©Ÿä¸Šé™
        if action == 1 or self.day >= self.max_steps - 1:
            # =========================================================
            # ğŸ”§ è§£è€¦çå‹µè¨ˆç®—ï¼šç„¡è«–ä½•æ™‚çµç®—ï¼Œéƒ½å¾€å¾Œçœ‹å›ºå®š REWARD_LOOKAHEAD å¤©
            # =========================================================
            lookahead_end = min(self.day + self.REWARD_LOOKAHEAD, self.DATA_BUFFER)
            future_returns = self.current_episode['returns'][self.day:lookahead_end]
            
            future_max = np.max(future_returns) if len(future_returns) > 0 else current_return
            future_min = np.min(future_returns) if len(future_returns) > 0 else current_return
            
            # 1. åŸºç¤çå‹µï¼šç•¶å‰å ±é…¬ (ç²åˆ© 10% = +1.0, è™§ 5% = -0.5)
            base_reward = (current_return - 1.0) * 10
            
            # 2. éŒ¯éé«˜é»çš„æ‡²ç½° / è³£åœ¨é«˜é»çš„çå‹µ
            if future_max > current_return + 0.01:  # æœªä¾†é‚„æœƒæ¼² >1%
                # éŒ¯éçš„æ¼²å¹…ï¼Œè¼•å¾®æ‡²ç½°
                penalty = (future_max - current_return) * 2
            else:
                # è³£åœ¨æ¥è¿‘æœ€é«˜é»ï¼é¡å¤–çå‹µ
                penalty = -0.5
            
            # 3. èº²éå¤§è·Œçš„çå‹µ
            if future_min < current_return - 0.05:  # æœªä¾†æœƒè·Œ >5%
                bonus = (current_return - future_min) * 5
            else:
                bonus = 0
            
            reward = base_reward - penalty + bonus
            done = True
        else:  # æŒæœ‰
            # å‹•æ…‹æŒæœ‰æ‡²ç½°ï¼ˆæº«å’Œç‰ˆï¼‰ï¼šåªæœ‰å¤§ç²åˆ©æ™‚æ‰è¼•å¾®æ‡²ç½°
            if current_return >= 1.10:  # å·²ç²åˆ© 10% ä»¥ä¸Š
                reward = -0.01  # è¼•å¾®æ‡²ç½°
            elif current_return >= 1.05:  # ç²åˆ© 5-10%
                reward = -0.002  # éå¸¸è¼•å¾®æ‡²ç½°
            else:  # ç²åˆ© <5% æˆ–è™§æ
                reward = 0.0  # ä¸æ‡²ç½°
            self.day += 1
            done = False
        
        # å®‰å…¨ç´¢å¼•ï¼šç¢ºä¿ä¸è¶…é max_steps (è§€æ¸¬ç”¨)ï¼Œä½†çå‹µè¨ˆç®—å¯ç”¨ DATA_BUFFER
        obs_idx = min(self.day, self.max_steps - 1)
        obs = np.concatenate([self.current_episode['features'][obs_idx], 
                              [self.current_episode['returns'][obs_idx]]]).astype(np.float32)
        return obs, reward, done, False, {}



# =============================================================================
# 5. Pre-training æµç¨‹
# =============================================================================
def run_pretraining(train_data: dict, models_path: str, device: str,
                    pretrain_buy_steps: int = 1_000_000, pretrain_sell_steps: int = 500_000,
                    train_buy: bool = True, train_sell: bool = True):
    """åŸ·è¡Œé è¨“ç·´ (å« TensorBoard æ—¥èªŒè¨˜éŒ„)
    
    Args:
        train_data: è¨“ç·´è³‡æ–™å­—å…¸
        models_path: æ¨¡å‹å„²å­˜è·¯å¾‘
        device: é‹ç®—è£ç½® (cuda/cpu)
        pretrain_buy_steps: Buy Agent é è¨“ç·´æ­¥æ•¸ (default: 1,000,000)
        pretrain_sell_steps: Sell Agent é è¨“ç·´æ­¥æ•¸ (default: 500,000)
        train_buy: æ˜¯å¦è¨“ç·´ Buy Agent (default: True)
        train_sell: æ˜¯å¦è¨“ç·´ Sell Agent (default: True)
    """
    print(f"\n[System] Starting Pre-training with {len(train_data)} indices...")
    
    # å»ºç«‹æ—¥èªŒç›®éŒ„
    tensorboard_log = "./tensorboard_logs/"
    os.makedirs(tensorboard_log, exist_ok=True)
    os.makedirs(os.path.join(models_path, "best_pretrain"), exist_ok=True)
    
    n_envs = min(8, max(1, multiprocessing.cpu_count() - 1))
    print(f"[System] CPU cores: {multiprocessing.cpu_count()}, Using {n_envs} envs")
    
    ppo_params = {
        "learning_rate": 0.0001, 
        "n_steps": max(128, 2048 // n_envs),
        "batch_size": 512, 
        "ent_coef": 0.01, 
        "device": device,
        "policy_kwargs": dict(net_arch=[64, 64, 64]), 
        "verbose": 1,
        "tensorboard_log": tensorboard_log  # å•Ÿç”¨ TensorBoard
    }
    
    buy_model = None
    sell_model = None
    
    # =========================================================================
    # Buy Agent
    # =========================================================================
    if train_buy:
        print("\nğŸ›’ Training Buy Agent (Base Model)...")
        buy_env = make_vec_env(BuyEnvHybrid, n_envs=n_envs, vec_env_cls=SubprocVecEnv,
                               env_kwargs={'data_dict': train_data, 'is_training': True})
        
        # å»ºç«‹è©•ä¼°ç’°å¢ƒ
        eval_buy_env = make_vec_env(BuyEnvHybrid, n_envs=1, vec_env_cls=DummyVecEnv,
                                    env_kwargs={'data_dict': train_data, 'is_training': False})
        
        buy_model = PPO("MlpPolicy", buy_env, **ppo_params)
        
        # Callbacks
        buy_callbacks = CallbackList([
            CheckpointCallback(save_freq=80000, save_path=models_path, name_prefix="ppo_buy_base"),
            EvalCallback(eval_buy_env, best_model_save_path=os.path.join(models_path, "best_pretrain", "buy"),
                         log_path="./logs/", eval_freq=10000, n_eval_episodes=50, 
                         deterministic=True)
        ])
        
        buy_model.learn(total_timesteps=pretrain_buy_steps, callback=buy_callbacks, tb_log_name="buy_pretrain")
        
        # è¤‡è£½ best model ä½œç‚º base model (è€Œéä½¿ç”¨æœ€å¾Œä¸€æ­¥çš„æ¨¡å‹)
        best_buy_path = os.path.join(models_path, "best_pretrain", "buy", "best_model.zip")
        buy_base_path = os.path.join(models_path, "ppo_buy_base.zip")
        if os.path.exists(best_buy_path):
            shutil.copy(best_buy_path, buy_base_path)
            print(f"[Pre-train] âœ… Buy Agent: Copied BEST model to {buy_base_path}")
        else:
            buy_model.save(os.path.join(models_path, "ppo_buy_base"))
            print(f"[Pre-train] âš ï¸ Buy Agent: Best model not found, saved last step model")
        
        buy_env.close()
        eval_buy_env.close()
    else:
        print("\n[Skip] Buy Agent pre-training (train_buy=False)")
    
    # =========================================================================
    # Sell Agent
    # =========================================================================
    if train_sell:
        print("\nğŸ’° Training Sell Agent (Base Model)...")
        sell_env = make_vec_env(SellEnvHybrid, n_envs=n_envs, vec_env_cls=SubprocVecEnv,
                                env_kwargs={'data_dict': train_data})
        
        # å»ºç«‹è©•ä¼°ç’°å¢ƒ
        eval_sell_env = make_vec_env(SellEnvHybrid, n_envs=1, vec_env_cls=DummyVecEnv,
                                     env_kwargs={'data_dict': train_data})
        
        sell_model = PPO("MlpPolicy", sell_env, **ppo_params)
        
        # Callbacks
        sell_callbacks = CallbackList([
            CheckpointCallback(save_freq=80000, save_path=models_path, name_prefix="ppo_sell_base"),
            EvalCallback(eval_sell_env, best_model_save_path=os.path.join(models_path, "best_pretrain"),
                         log_path="./logs/", eval_freq=10000, n_eval_episodes=50, 
                         deterministic=True)
        ])
        
        sell_model.learn(total_timesteps=pretrain_sell_steps, callback=sell_callbacks, tb_log_name="sell_pretrain")
        
        # è¤‡è£½ best model ä½œç‚º base model (è€Œéä½¿ç”¨æœ€å¾Œä¸€æ­¥çš„æ¨¡å‹)
        best_sell_path = os.path.join(models_path, "best_pretrain", "best_model.zip")
        sell_base_path = os.path.join(models_path, "ppo_sell_base.zip")
        if os.path.exists(best_sell_path):
            shutil.copy(best_sell_path, sell_base_path)
            print(f"[Pre-train] âœ… Sell Agent: Copied BEST model to {sell_base_path}")
        else:
            sell_model.save(os.path.join(models_path, "ppo_sell_base"))
            print(f"[Pre-train] âš ï¸ Sell Agent: Best model not found, saved last step model")
        
        sell_env.close()
        eval_sell_env.close()
    else:
        print("\n[Skip] Sell Agent pre-training (train_sell=False)")
    
    print("[System] Pre-training Completed.")
    return buy_model, sell_model


# =============================================================================
# 6. Fine-tuning æµç¨‹ (Transfer Learning)
# =============================================================================
def run_finetuning(twii_finetune_data: dict, twii_eval_data: dict, models_path: str, device: str,
                   finetune_buy_steps: int = 1_000_000, finetune_sell_steps: int = 500_000,
                   train_buy: bool = True, train_sell: bool = True):
    """
    é‡å° ^TWII é€²è¡Œå¾®èª¿ (å« TensorBoard æ—¥èªŒè¨˜éŒ„)
    - è¼‰å…¥é è¨“ç·´æ¬Šé‡
    - ä½¿ç”¨è¼ƒä½çš„ Learning Rate (1e-5)
    - å¯è‡ªè¨‚è¨“ç·´æ­¥æ•¸
    - EvalCallback ç›£æ§é©—è­‰é›†è¡¨ç¾
    
    Args:
        finetune_buy_steps: Buy Agent å¾®èª¿æ­¥æ•¸ (default: 1,000,000)
        finetune_sell_steps: Sell Agent å¾®èª¿æ­¥æ•¸ (default: 300,000)
        train_buy: æ˜¯å¦è¨“ç·´ Buy Agent (default: True)
        train_sell: æ˜¯å¦è¨“ç·´ Sell Agent (default: True)
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ Phase 4: Fine-tuning for ^TWII (with TensorBoard)")
    print("=" * 60)
    
    # å»ºç«‹æ—¥èªŒç›®éŒ„
    tensorboard_log = "./tensorboard_logs/"
    os.makedirs(tensorboard_log, exist_ok=True)
    os.makedirs(os.path.join(models_path, "best_tuned"), exist_ok=True)
    os.makedirs("./logs/", exist_ok=True)
    
    n_envs = min(4, max(1, multiprocessing.cpu_count() - 1))
    
    # Fine-tuning åƒæ•¸ï¼ˆTransfer Learning é—œéµï¼‰
    finetune_params = {
        "learning_rate": 1e-5,  # åŸæœ¬çš„ 1/10
        "n_steps": 256,
        "batch_size": 128,
        "ent_coef": 0.005,
        "device": device,
        "verbose": 1
    }
    
    buy_model = None
    sell_model = None
    
    # =========================================================================
    # Fine-tune Buy Agent
    # =========================================================================
    if train_buy:
        print("\n[Fine-tune] Loading ppo_buy_base and fine-tuning for ^TWII...")
        
        buy_base_path = os.path.join(models_path, "ppo_buy_base.zip")
        if not os.path.exists(buy_base_path):
            print(f"[Error] Base model not found: {buy_base_path}")
            return None, None
    
        buy_env = make_vec_env(BuyEnvHybrid, n_envs=n_envs, vec_env_cls=SubprocVecEnv,
                               env_kwargs={'data_dict': twii_finetune_data, 'is_training': True})
        
        # å»ºç«‹è©•ä¼°ç’°å¢ƒ (ä½¿ç”¨ Backtest æ•¸æ“šå­é›†)
        eval_buy_env = make_vec_env(BuyEnvHybrid, n_envs=1, vec_env_cls=DummyVecEnv,
                                    env_kwargs={'data_dict': twii_eval_data, 'is_training': False})
        
        buy_model = PPO.load(buy_base_path, env=buy_env, device=device,
                             tensorboard_log=tensorboard_log)
        buy_model.learning_rate = finetune_params["learning_rate"]
        buy_model.ent_coef = finetune_params["ent_coef"]
        
        # Callbacks
        buy_callbacks = CallbackList([
            CheckpointCallback(save_freq=100000, save_path=models_path, name_prefix="ppo_buy_finetune"),
            EvalCallback(eval_buy_env, best_model_save_path=os.path.join(models_path, "best_tuned", "buy"),
                         log_path="./logs/", eval_freq=10000, n_eval_episodes=30, 
                         deterministic=True)
        ])
        
        print(f"[Fine-tune] Training Buy Agent for {finetune_buy_steps:,} steps (LR: {finetune_params['learning_rate']})")
        buy_model.learn(total_timesteps=finetune_buy_steps, callback=buy_callbacks, 
                        tb_log_name="buy_finetune", reset_num_timesteps=False)
        
        # è¤‡è£½ best model ä½œç‚º final model (è€Œéä½¿ç”¨æœ€å¾Œä¸€æ­¥çš„æ¨¡å‹)
        best_buy_path = os.path.join(models_path, "best_tuned", "buy", "best_model.zip")
        buy_final_path = os.path.join(models_path, "ppo_buy_twii_final.zip")
        if os.path.exists(best_buy_path):
            shutil.copy(best_buy_path, buy_final_path)
            print(f"[Fine-tune] âœ… Buy Agent: Copied BEST model to {buy_final_path}")
        else:
            buy_model.save(os.path.join(models_path, "ppo_buy_twii_final"))
            print(f"[Fine-tune] âš ï¸ Buy Agent: Best model not found, saved last step model")
        
        buy_env.close()
        eval_buy_env.close()
    else:
        print("\n[Skip] Buy Agent fine-tuning (train_buy=False)")
    
    # =========================================================================
    # Fine-tune Sell Agent
    # =========================================================================
    if train_sell:
        print("\n[Fine-tune] Loading ppo_sell_base and fine-tuning for ^TWII...")
        
        sell_base_path = os.path.join(models_path, "ppo_sell_base.zip")
        sell_env = make_vec_env(SellEnvHybrid, n_envs=n_envs, vec_env_cls=SubprocVecEnv,
                                env_kwargs={'data_dict': twii_finetune_data})
        
        # å»ºç«‹è©•ä¼°ç’°å¢ƒ (ä½¿ç”¨ Backtest æ•¸æ“šå­é›†)
        eval_sell_env = make_vec_env(SellEnvHybrid, n_envs=1, vec_env_cls=DummyVecEnv,
                                     env_kwargs={'data_dict': twii_eval_data})
        
        sell_model = PPO.load(sell_base_path, env=sell_env, device=device,
                              tensorboard_log=tensorboard_log)
        sell_model.learning_rate = finetune_params["learning_rate"]
        sell_model.ent_coef = finetune_params["ent_coef"]
        
        # Callbacks
        sell_callbacks = CallbackList([
            CheckpointCallback(save_freq=50000, save_path=models_path, name_prefix="ppo_sell_finetune"),
            EvalCallback(eval_sell_env, best_model_save_path=os.path.join(models_path, "best_tuned", "sell"),
                         log_path="./logs/", eval_freq=10000, n_eval_episodes=30, 
                         deterministic=True)
        ])
        
        print(f"[Fine-tune] Training Sell Agent for {finetune_sell_steps:,} steps (LR: {finetune_params['learning_rate']})")
        sell_model.learn(total_timesteps=finetune_sell_steps, callback=sell_callbacks, 
                         tb_log_name="sell_finetune", reset_num_timesteps=False)
        
        # è¤‡è£½ best model ä½œç‚º final model (è€Œéä½¿ç”¨æœ€å¾Œä¸€æ­¥çš„æ¨¡å‹)
        best_sell_path = os.path.join(models_path, "best_tuned", "sell", "best_model.zip")
        sell_final_path = os.path.join(models_path, "ppo_sell_twii_final.zip")
        if os.path.exists(best_sell_path):
            shutil.copy(best_sell_path, sell_final_path)
            print(f"[Fine-tune] âœ… Sell Agent: Copied BEST model to {sell_final_path}")
        else:
            sell_model.save(os.path.join(models_path, "ppo_sell_twii_final"))
            print(f"[Fine-tune] âš ï¸ Sell Agent: Best model not found, saved last step model")
        
        sell_env.close()
        eval_sell_env.close()
    else:
        print("\n[Skip] Sell Agent fine-tuning (train_sell=False)")
    
    print("\n[System] Fine-tuning Completed!")
    return buy_model, sell_model


# =============================================================================
# 7. Backtesting æµç¨‹
# =============================================================================
class HybridBacktester:
    """Hybrid Trading System Backtester"""
    
    def __init__(self, buy_model, sell_model, initial_capital=1_000_000):
        self.buy_model = buy_model
        self.sell_model = sell_model
        self.initial_capital = initial_capital
        
        # äº¤æ˜“è¨˜éŒ„
        self.trades = []
        self.equity_curve = []
        self.buy_signals = []  # (date, price)
        self.sell_signals = [] # (date, price)
    
    def run(self, df: pd.DataFrame) -> dict:
        """
        åŸ·è¡Œå›æ¸¬
        
        Args:
            df: åŒ…å«ç‰¹å¾µçš„ DataFrame
        
        Returns:
            ç¸¾æ•ˆæŒ‡æ¨™å­—å…¸
        """
        capital = self.initial_capital
        position = None  # {'shares': int, 'buy_price': float, 'buy_date': date}
        
        dates = df.index.tolist()
        closes = df['Close'].values
        
        # å»ºç«‹è§€å¯Ÿè³‡æ–™
        features = df[FEATURE_COLS].values.astype(np.float32)
        buy_signals_mask = df['Signal_Buy_Filter'].values
        
        for i in tqdm(range(len(df)), desc="Backtesting"):
            date = dates[i]
            price = closes[i]
            
            # è¨˜éŒ„ç•¶æ—¥æ·¨å€¼
            if position:
                current_value = capital + position['shares'] * price
            else:
                current_value = capital
            self.equity_curve.append({'date': date, 'value': current_value})
            
            # æŒæœ‰ä¸­ï¼šæª¢æŸ¥è³£å‡º
            if position is not None:
                hold_days = i - position['buy_idx']
                current_return = price / position['buy_price']
                
                # æº–å‚™ Sell Agent è§€å¯Ÿ
                sell_obs = np.concatenate([features[i], [current_return]]).astype(np.float32)
                
                # é æ¸¬
                action, _ = self.sell_model.predict(sell_obs.reshape(1, -1), deterministic=True)
                
                # åœææ¢ä»¶ æˆ– AI æ±ºå®šè³£å‡º æˆ– æŒæœ‰è¶…é 120 å¤©
                stop_loss = current_return < 0.92  # -8% åœæ
                should_sell = action[0] == 1 or stop_loss
                
                if should_sell:
                    # åŸ·è¡Œè³£å‡º
                    sell_value = position['shares'] * price
                    profit = sell_value - position['shares'] * position['buy_price']
                    capital += sell_value
                    
                    self.trades.append({
                        'buy_date': position['buy_date'],
                        'buy_price': position['buy_price'],
                        'sell_date': date,
                        'sell_price': price,
                        'return': current_return - 1,
                        'profit': profit
                    })
                    self.sell_signals.append((date, price))
                    
                    position = None
            
            # ç©ºæ‰‹ï¼šæª¢æŸ¥è²·å…¥
            elif buy_signals_mask[i]:
                # æº–å‚™ Buy Agent è§€å¯Ÿ
                buy_obs = features[i].reshape(1, -1)
                action, _ = self.buy_model.predict(buy_obs, deterministic=True)
                
                if action[0] == 1:  # Buy
                    # åŸ·è¡Œè²·å…¥ï¼ˆä½¿ç”¨ 90% è³‡é‡‘ï¼‰
                    invest_amount = capital * 0.9
                    shares = int(invest_amount / price)
                    
                    if shares > 0:
                        cost = shares * price
                        capital -= cost
                        
                        position = {
                            'shares': shares,
                            'buy_price': price,
                            'buy_date': date,
                            'buy_idx': i
                        }
                        self.buy_signals.append((date, price))
        
        # è¨ˆç®—ç¸¾æ•ˆæŒ‡æ¨™
        return self._calculate_metrics(df)
    
    def _calculate_metrics(self, df: pd.DataFrame) -> dict:
        """è¨ˆç®—ç¸¾æ•ˆæŒ‡æ¨™"""
        if not self.equity_curve:
            return {}
        
        equity_df = pd.DataFrame(self.equity_curve)
        equity_df['date'] = pd.to_datetime(equity_df['date'])
        equity_df.set_index('date', inplace=True)
        
        # ç¸½å ±é…¬ç‡
        initial = self.initial_capital
        final = equity_df['value'].iloc[-1]
        total_return = (final - initial) / initial
        
        # å¹´åŒ–å ±é…¬ç‡
        days = (equity_df.index[-1] - equity_df.index[0]).days
        years = days / 365.0
        annualized_return = (1 + total_return) ** (1 / years) - 1 if years > 0 else 0
        
        # å¤æ™®å€¼ (å‡è¨­ç„¡é¢¨éšªåˆ©ç‡ = 2%)
        daily_returns = equity_df['value'].pct_change().dropna()
        if len(daily_returns) > 0 and daily_returns.std() > 0:
            sharpe = (daily_returns.mean() * 252 - 0.02) / (daily_returns.std() * np.sqrt(252))
        else:
            sharpe = 0
        
        # æœ€å¤§å›æ’¤
        rolling_max = equity_df['value'].cummax()
        drawdown = (equity_df['value'] - rolling_max) / rolling_max
        max_drawdown = drawdown.min()
        
        # å‹ç‡
        if self.trades:
            wins = sum(1 for t in self.trades if t['return'] > 0)
            win_rate = wins / len(self.trades)
        else:
            win_rate = 0
        
        return {
            'initial_capital': initial,
            'final_value': final,
            'total_return': total_return,
            'annualized_return': annualized_return,
            'sharpe_ratio': sharpe,
            'max_drawdown': max_drawdown,
            'total_trades': len(self.trades),
            'win_rate': win_rate,
            'equity_df': equity_df
        }


def run_backtesting(twii_backtest_df: pd.DataFrame, buy_model, sell_model, 
                    results_path: str, benchmark_df: pd.DataFrame) -> dict:
    """
    åŸ·è¡Œå›æ¸¬ä¸¦è¦–è¦ºåŒ–çµæœ
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š Phase 4: Backtesting (2023-Present)")
    print("=" * 60)
    
    # åŸ·è¡Œå›æ¸¬
    backtester = HybridBacktester(buy_model, sell_model, initial_capital=1_000_000)
    metrics = backtester.run(twii_backtest_df)
    
    if not metrics:
        print("[Error] Backtesting failed!")
        return {}
    
    # å°å‡ºç¸¾æ•ˆ
    print("\n" + "-" * 60)
    print("ğŸ“ˆ Performance Summary")
    print("-" * 60)
    print(f"  åˆå§‹è³‡é‡‘: ${metrics['initial_capital']:,.0f}")
    print(f"  æœ€çµ‚æ·¨å€¼: ${metrics['final_value']:,.0f}")
    print(f"  ç¸½å ±é…¬ç‡: {metrics['total_return']*100:.2f}%")
    print(f"  å¹´åŒ–å ±é…¬: {metrics['annualized_return']*100:.2f}%")
    print(f"  å¤æ™®å€¼:   {metrics['sharpe_ratio']:.2f}")
    print(f"  æœ€å¤§å›æ’¤: {metrics['max_drawdown']*100:.2f}%")
    print(f"  äº¤æ˜“æ¬¡æ•¸: {metrics['total_trades']}")
    print(f"  å‹ç‡:     {metrics['win_rate']*100:.1f}%")
    print("-" * 60)
    
    # ==========================================================================
    # è¦–è¦ºåŒ–
    # ==========================================================================
    fig, axes = plt.subplots(2, 1, figsize=(14, 10))
    
    # å­åœ– 1: Portfolio Value vs Benchmark
    ax1 = axes[0]
    
    equity_df = metrics['equity_df']
    
    # Portfolio
    ax1.plot(equity_df.index, equity_df['value'], label='Hybrid System', 
             color='blue', linewidth=2)
    
    # Benchmark (Buy & Hold)
    bench_slice = benchmark_df.loc[equity_df.index[0]:equity_df.index[-1]]['Close']
    bench_normalized = bench_slice / bench_slice.iloc[0] * metrics['initial_capital']
    ax1.plot(bench_normalized.index, bench_normalized.values, 
             label='^TWII Buy & Hold', color='gray', linewidth=1.5, alpha=0.7)
    
    ax1.set_title('Portfolio Value vs Benchmark (2023-Present)', fontsize=14)
    ax1.set_ylabel('Portfolio Value ($)')
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)
    
    # å­åœ– 2: Price with Buy/Sell Signals
    ax2 = axes[1]
    
    price_slice = twii_backtest_df['Close']
    ax2.plot(price_slice.index, price_slice.values, label='^TWII Close', 
             color='black', linewidth=1)
    
    # Buy signals (ç´…è‰²ä¸‰è§’å½¢)
    if backtester.buy_signals:
        buy_dates, buy_prices = zip(*backtester.buy_signals)
        ax2.scatter(buy_dates, buy_prices, marker='^', color='red', s=100, 
                    label='Buy Signal', zorder=5)
    
    # Sell signals (ç¶ è‰²ä¸‰è§’å½¢)
    if backtester.sell_signals:
        sell_dates, sell_prices = zip(*backtester.sell_signals)
        ax2.scatter(sell_dates, sell_prices, marker='v', color='green', s=100, 
                    label='Sell Signal', zorder=5)
    
    ax2.set_title('^TWII Price with Trading Signals', fontsize=14)
    ax2.set_ylabel('Price')
    ax2.set_xlabel('Date')
    ax2.legend(loc='upper left')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # å„²å­˜åœ–è¡¨
    save_path = os.path.join(results_path, 'final_performance.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\n[System] Chart saved to: {save_path}")
    
    plt.close()
    
    return metrics


# =============================================================================
# Main Execution
# =============================================================================
if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("  ğŸš€ Hybrid Trading System - Full Pipeline")
    print("=" * 70)
    
    # =========================================================================
    # Phase 0: Setup
    # =========================================================================
    PROJECT_PATH, MODELS_PATH, RESULTS_PATH, DATA_PATH, device = setup_environment()
    
    # Check if base models exist
    buy_base_exists = os.path.exists(os.path.join(MODELS_PATH, "ppo_buy_base.zip"))
    sell_base_exists = os.path.exists(os.path.join(MODELS_PATH, "ppo_sell_base.zip"))
    
    # =========================================================================
    # Phase 1-3: Pre-training (if needed)
    # =========================================================================
    if not buy_base_exists or not sell_base_exists:
        print("\n[System] Base models not found. Running Phase 1-3...")
        
        # [v6.0] LSTM å·²ç§»é™¤ï¼Œä¸å†è¼‰å…¥ LSTM æ¨¡å‹
        
        # Download data
        raw_data = fetch_index_data(DATA_PATH, start_date="2000-01-01")
        
        # Calculate features
        train_data = {}
        benchmark_df = raw_data.get("^TWII")
        for ticker, df in raw_data.items():
            try:
                processed = calculate_features(df, benchmark_df, ticker, use_cache=True)
                if len(processed) > 100:
                    train_data[ticker] = processed
            except Exception as e:
                print(f"  Error: {ticker} - {e}")
        
        # Pre-training
        run_pretraining(train_data, MODELS_PATH, device)
    else:
        print("\n[System] Base models found. Skipping Phase 1-3.")
    
    # =========================================================================
    # Phase 4: Fine-tuning & Backtesting
    # =========================================================================
    print("\n" + "=" * 70)
    print("  ğŸ“Œ Phase 4: Fine-tuning & Backtesting for ^TWII")
    print("=" * 70)
    
    # [v6.0] LSTM å·²ç§»é™¤ï¼Œä¸å†è¼‰å…¥ LSTM æ¨¡å‹
    
    # Load ^TWII data with features
    print("\n[System] Loading ^TWII data...")
    cache_path = os.path.join(CACHE_DIR, "_TWII_features.pkl")
    
    if os.path.exists(cache_path):
        print(f"[Cache] Loading ^TWII features...")
        with open(cache_path, 'rb') as f:
            twii_full_df = pickle.load(f)
    else:
        print("[Compute] Downloading and processing ^TWII...")
        twii_raw = yf.download("^TWII", start="2000-01-01", auto_adjust=True, progress=False)
        twii_full_df = calculate_features(twii_raw, twii_raw, ticker="^TWII", use_cache=True)
    
    print(f"[System] ^TWII data: {len(twii_full_df)} rows")
    print(f"[System] Date range: {twii_full_df.index[0].strftime('%Y-%m-%d')} ~ {twii_full_df.index[-1].strftime('%Y-%m-%d')}")
    
    # =========================================================================
    # Split data
    # =========================================================================
    print(f"\n[System] Splitting data at {SPLIT_DATE}...")
    
    split_date = pd.Timestamp(SPLIT_DATE)
    twii_finetune_df = twii_full_df[twii_full_df.index < split_date]
    twii_backtest_df = twii_full_df[twii_full_df.index >= split_date]
    
    print(f"  Fine-tuning set: {len(twii_finetune_df)} rows (< {SPLIT_DATE})")
    print(f"  Backtest set:    {len(twii_backtest_df)} rows (>= {SPLIT_DATE})")
    
    # =========================================================================
    # Fine-tuning
    # =========================================================================
    finetune_data = {'^TWII': twii_finetune_df}
    eval_data = {'^TWII': twii_backtest_df}  # ä½¿ç”¨ Backtest æ•¸æ“šä½œç‚ºé©—è­‰é›†
    buy_model, sell_model = run_finetuning(finetune_data, eval_data, MODELS_PATH, device)
    
    if buy_model is None:
        print("[Error] Fine-tuning failed!")
        sys.exit(1)
    
    # =========================================================================
    # Backtesting
    # =========================================================================
    # è¼‰å…¥ Fine-tuned æ¨¡å‹
    buy_final = PPO.load(os.path.join(MODELS_PATH, "ppo_buy_twii_final.zip"))
    sell_final = PPO.load(os.path.join(MODELS_PATH, "ppo_sell_twii_final.zip"))
    
    metrics = run_backtesting(twii_backtest_df, buy_final, sell_final, 
                               RESULTS_PATH, twii_full_df)
    
    # =========================================================================
    # Final Summary
    # =========================================================================
    print("\n" + "=" * 70)
    print("  âœ… [System] All Phases Completed.")
    print("=" * 70)
    print(f"""
    ğŸ“Š Final Results:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ç¸½å ±é…¬ç‡:   {metrics.get('total_return', 0)*100:.2f}%
    å¹´åŒ–å ±é…¬:   {metrics.get('annualized_return', 0)*100:.2f}%
    å¤æ™®å€¼:     {metrics.get('sharpe_ratio', 0):.2f}
    æœ€å¤§å›æ’¤:   {metrics.get('max_drawdown', 0)*100:.2f}%
    äº¤æ˜“æ¬¡æ•¸:   {metrics.get('total_trades', 0)}
    å‹ç‡:       {metrics.get('win_rate', 0)*100:.1f}%
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    ğŸ“ Output Files:
    - models_hybrid/ppo_buy_twii_final.zip
    - models_hybrid/ppo_sell_twii_final.zip
    - results_hybrid/final_performance.png
    
    ğŸ“ˆ TensorBoard è¨“ç·´ç›£æ§ï¼š
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤é–‹å•Ÿ TensorBoardï¼š
    
        tensorboard --logdir ./tensorboard_logs/
    
    é–‹å•Ÿç€è¦½å™¨å‰å¾€ http://localhost:6006
    æŸ¥çœ‹ Loss, Entropy, Reward ç­‰è¨“ç·´æ›²ç·šã€‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """)
