#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
================================================================================
US Tech Stock - PPO Classifier Offline Evaluation Script
================================================================================
ç›´æ¥è¼‰å…¥å·²è¨“ç·´å¥½çš„ PPO Buy Agent (best_model.zip ç­‰)ï¼Œå° Validation å€é–“é€²è¡Œé›¢ç·šæ¨è«–ã€‚
ä¸é‡æ–°è¨“ç·´ã€ä¸è§¸ç™¼ learn()ã€ä¸ä¿®æ”¹åˆ†ä½ˆï¼Œä»¥å…¨é‡çœŸå¯¦ Validation é€²è¡Œè©•ä¼°ã€‚

è¼¸å‡ºæ ¼å¼èˆ‡ Metrics 100% èˆ‡ sklearn åˆ†é¡å™¨å°é½Šï¼Œä»¥ä¾¿ç›´æ¥æ¯”è¼ƒå…©è€…ã€‚
================================================================================
"""

import os
import sys
import json
import argparse
from datetime import datetime
import numpy as np
import pandas as pd
import warnings

from stable_baselines3 import PPO
import torch

from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, 
                             roc_auc_score, average_precision_score, confusion_matrix)

# è§£æ±ºä¸€äº› torch è¼‰å…¥å¯èƒ½ç”¢ç”Ÿçš„è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)

# å°‡å°ˆæ¡ˆæ ¹ç›®éŒ„åŠ åˆ° sys.pathï¼Œä»¥ä¾¿ import å…±ç”¨æ¨¡çµ„
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

try:
    from train_us_tech_buy_agent import (fetch_all_stock_data, calculate_features, 
                                         FEATURE_COLS, VAL_RANGE, BENCHMARK)
except ImportError as e:
    print(f"âŒ ç„¡æ³•å¾ train_us_tech_buy_agent.py è¼‰å…¥å…±ç”¨é‚è¼¯: {e}")
    print("è«‹ç¢ºä¿è…³æœ¬æœ‰æ”¾ç½®åœ¨æ­£ç¢ºçš„æ ¹ç›®éŒ„ä¸‹å±¤ scripts è³‡æ–™å¤¾å…§ã€‚")
    sys.exit(1)


def parse_args():
    parser = argparse.ArgumentParser(description="Evaluate PPO Buy Agent (Next 20d Max >= 10%) Offline")
    
    # å¿…å¡«æ¨¡å‹åƒæ•¸
    parser.add_argument("--model-path", type=str, required=True, 
                        help="å¿…å¡«ï¼šPPO å„²å­˜çš„æ¨¡å‹å£“ç¸®æª”è·¯å¾‘ (ä¾‹å¦‚: models_v5/ppo_buy_base_us_tech.zip)")
                        
    # è³‡æ–™åƒæ•¸
    parser.add_argument("--tickers", nargs="+", 
                        default=["NVDA", "MSFT", "AAPL", "AMZN", "META", "AVGO", "GOOGL", "TSLA", "NFLX", "PLTR"],
                        help="ç›®æ¨™è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨")
    parser.add_argument("--val-start-date", type=str, help="é©—è­‰å€é–“èµ·å§‹æ—¥ (æœªæä¾›å‰‡ç”¨ VAL_RANGE)")
    parser.add_argument("--val-end-date", type=str, help="é©—è­‰å€é–“çµæŸæ—¥ (æœªæä¾›å‰‡ç”¨ VAL_RANGE)")
    
    # è©•ä¼°åƒæ•¸
    parser.add_argument("--threshold", type=float, default=0.5, help="ç”¨ä¾†æ±ºå®š y_pred çš„æ­£é¡é–¾å€¼ (é è¨­ 0.5)")
    parser.add_argument("--seed", type=int, default=42, help="éš¨æ©Ÿç¨®å­ (ä¸å½±éŸ¿æŠ½æ¨£ï¼Œåƒ…å›ºå®šæ’åº)")
    
    # ç’°å¢ƒèˆ‡è¼¸å‡ºåƒæ•¸
    parser.add_argument("--output-dir", default=os.path.join(ROOT_DIR, "output_eval_ppo"), 
                        help="è©•ä¼°çµæœèˆ‡æŒ‡æ¨™è¼¸å‡ºæ ¹ç›®éŒ„")
    parser.add_argument("--no-cache", action="store_true", help="é—œé–‰ç‰¹å¾µå¿«å–")
    parser.add_argument("--dry-run", action="store_true", 
                        help="åªæª¢æŸ¥è³‡æ–™èˆ‡ç¶­åº¦ï¼Œå°å‡ºé©—è­‰ç¸½æ•¸å¾ŒçµæŸ (ä¸è¼‰å…¥æ¨¡å‹æ¨è«–)")
    
    return parser.parse_args()


def prepare_validation_data(args, val_range):
    """
    è¼‰å…¥ä¸¦è™•ç†è³‡æ–™ï¼Œè¼¸å‡º Validation é©—è­‰é›†å…¨é‡çœŸå¯¦åˆ†ä½ˆ
    """
    all_raw_data = fetch_all_stock_data()
    benchmark_df = all_raw_data.get(BENCHMARK)
    if benchmark_df is None:
        raise ValueError(f"ç„¡æ³•è¼‰å…¥ benchmark {BENCHMARK} çš„è³‡æ–™ã€‚")
        
    use_cache = not args.no_cache
    val_dfs = []
    
    print("\nğŸ” æ­£åœ¨ç”Ÿæˆ/è¼‰å…¥ç‰¹å¾µèˆ‡æ“·å– Validation å€æ®µ...")
    val_start, val_end = val_range
    
    for ticker in args.tickers:
        if ticker not in all_raw_data:
            print(f"  âš ï¸ {ticker} åŸå§‹è³‡æ–™ä¸å­˜åœ¨ï¼Œè·³éã€‚")
            continue
            
        df_raw = all_raw_data[ticker]
        df_features = calculate_features(df_raw, benchmark_df, ticker=ticker, use_cache=use_cache)
        
        # 1. ç¢ºä¿ç›®æ¨™æ¬„ä½å­˜åœ¨ä¸¦éæ¿¾ NaN
        if 'Next_20d_Max' not in df_features.columns:
            print(f"  âš ï¸ {ticker} ç„¡ Next_20d_Max æ¬„ä½ï¼Œè·³éã€‚")
            continue
        df_features = df_features.dropna(subset=['Next_20d_Max'])
        
        # 2. é©—è­‰é›†æ™‚é–“åˆ‡åˆ†
        val_mask = (df_features.index >= pd.Timestamp(val_start)) & (df_features.index <= pd.Timestamp(val_end))
        df_val_tick = df_features[val_mask]
        
        if len(df_val_tick) == 0:
            print(f"  âš ï¸ {ticker} æ–¼é©—è­‰å€é–“ ({val_start} ~ {val_end}) å…§ç„¡ä»»ä½•æœ‰æ•ˆæ¨£æœ¬ï¼Œè·³éã€‚")
            continue
            
        # 3. è£œå……æ¨™è¨˜
        df_val_tick.loc[:, 'ticker'] = ticker
        df_val_tick.loc[:, 'date'] = df_val_tick.index.strftime('%Y-%m-%d')
        df_val_tick.loc[:, 'y'] = (df_val_tick['Next_20d_Max'] >= 0.10).astype(int)
        
        val_dfs.append(df_val_tick)
        
    df_val = pd.concat(val_dfs, ignore_index=True) if val_dfs else pd.DataFrame()
    return df_val


def print_val_stats(df_val, tickers):
    """å°å‡º Validation è³‡æ–™é›†çµ±è¨ˆè³‡è¨Š"""
    print("\nğŸ“Š Validation è³‡æ–™èˆ‡é¡åˆ¥æ¯”ä¾‹çµ±è¨ˆ")
    print("-" * 45)
    print(f"{'Ticker':<8} | {'Val (N)':<10} | {'Val Pos%':<10}")
    print("-" * 45)
    
    for tk in tickers:
        d_va = df_val[df_val['ticker'] == tk]
        va_len = len(d_va)
        if va_len > 0:
            va_pos = d_va['y'].mean()
            print(f"{tk:<8} | {va_len:<10} | {va_pos*100:6.2f}%")
        
    print("-" * 45)
    tot_va_len = len(df_val)
    tot_va_pos = df_val['y'].mean() if tot_va_len > 0 else 0
    print(f"{'TOTAL':<8} | {tot_va_len:<10} | {tot_va_pos*100:6.2f}%")
    print("-" * 45)


def get_ppo_probabilities(model, X_val_np):
    """
    å¾ PPO model ç²å¾—é æ¸¬çš„æ­£é¡æ©Ÿç‡ P(action=1|x)
    
    PPO å±¬æ–¼ Actor-Criticï¼Œé€£çºŒæ¨è«–æ™‚éœ€å‹•ç”¨ Policy çš„ get_distribution æ–¹æ³•
    è€Œä¸ä½¿ç”¨ env step ä¾†è¦é¿é‡æ–°é€£å‹•çš„å•é¡Œ
    """
    print("ğŸ§  æ­£åœ¨é€²è¡Œ PPO Offline Inference (no_grad)...")
    device = model.device
    
    # å°‡ Numpy Array è½‰æˆ PyTorch Tensorï¼ŒåŒæ™‚é€å¾€åŒè£ç½®
    obs_tensor = torch.tensor(X_val_np, dtype=torch.float32, device=device)
    
    # é—œé–‰æ¢¯åº¦é€²è¡Œå¿«é€Ÿé‹ç®—
    with torch.no_grad():
        # å°é€£çºŒçš„ observation ç²å¾—å…¶ Categorical åˆ†ä½ˆ
        distribution = model.policy.get_distribution(obs_tensor)
        # å–å¾—æ¯ä¸€å€‹ sample åœ¨ action=0 è·Ÿ action=1 ä¸Šçš„ softmax æ©Ÿç‡åˆ†ä½ˆ
        # .probs ç¶­åº¦ç‚º (batch_size, 2)
        probs = distribution.distribution.probs
        
        # æå– Action=1 (BUY) çš„æ©Ÿç‡
        y_proba = probs[:, 1].cpu().numpy()
        
    return y_proba


def calc_metrics(y_true, y_proba, threshold, prefix="Overall"):
    """è¨ˆç®—ä¸¦å›å‚³é©—è­‰é›†çš„å„ç¨®æŒ‡æ¨™ (çµ±ä¸€èˆ‡ Sklearn ç‰ˆç”¢å‡ºæ ¼å¼å°é½Š)"""
    metrics = {}
    y_pred = (y_proba >= threshold).astype(int)
    
    # é¿å… y_true å…¨ 0 æˆ–å…¨ 1 å°è‡´ auc å¤±æ•—
    has_mixed_classes = len(np.unique(y_true)) > 1
    
    metrics['Accuracy'] = float(accuracy_score(y_true, y_pred))
    metrics['Precision'] = float(precision_score(y_true, y_pred, zero_division=0))
    metrics['Recall'] = float(recall_score(y_true, y_pred, zero_division=0))
    metrics['F1'] = float(f1_score(y_true, y_pred, zero_division=0))
    
    metrics['ROC-AUC'] = float(roc_auc_score(y_true, y_proba)) if has_mixed_classes else None
    metrics['PR-AUC'] = float(average_precision_score(y_true, y_proba)) if has_mixed_classes else None
    
    metrics['Confusion Matrix'] = confusion_matrix(y_true, y_pred).tolist()
    
    # Precision@k (Top 1%, 5%, 10%)
    sort_idx = np.argsort(y_proba)[::-1]
    sorted_y_true = np.array(y_true)[sort_idx]
    
    for k_pct in [0.01, 0.05, 0.10]:
        k = max(1, int(len(y_true) * k_pct))
        top_k_y_true = sorted_y_true[:k]
        metrics[f'Precision@{int(k_pct*100)}%'] = float(np.mean(top_k_y_true))
        
    # Threshold sweep
    metrics['Threshold Sweep'] = {}
    for th in [0.5, 0.6, 0.7, 0.8, 0.9]:
        y_pred_th = (y_proba >= th).astype(int)
        metrics['Threshold Sweep'][f'Threshold={th}'] = {
            'Precision': float(precision_score(y_true, y_pred_th, zero_division=0)),
            'Recall': float(recall_score(y_true, y_pred_th, zero_division=0)),
            'F1': float(f1_score(y_true, y_pred_th, zero_division=0))
        }
        
    return metrics


def main():
    args = parse_args()
    np.random.seed(args.seed)
    
    # æ±ºå®šåˆ‡å‰²å€æ®µ
    val_range = (
        args.val_start_date if args.val_start_date else VAL_RANGE[0],
        args.val_end_date if args.val_end_date else VAL_RANGE[1]
    )
    
    print("=" * 60)
    print("ğŸš€ PPO Classifier Offline Evaluation (Validation Only)")
    print("=" * 60)
    print(f"  PPO Model   : {args.model_path}")
    print(f"  Target      : Next_20d_Max >= 10%")
    print(f"  Tickers     : {', '.join(args.tickers)}")
    print(f"  Val Range   : {val_range}")
    print(f"  Threshold   : {args.threshold}")
    print(f"  Dry Run     : {args.dry_run}")
    print("=" * 60)
    
    if not os.path.exists(args.model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æŒ‡å®šçš„æ¨¡å‹è·¯å¾‘: {args.model_path}")
        sys.exit(1)
    
    # 1. æº–å‚™è³‡æ–™
    df_val = prepare_validation_data(args, val_range)
    
    if len(df_val) == 0:
        print("âŒ é©—è­‰è³‡æ–™é›†ç‚ºç©ºï¼Œè«‹æª¢æŸ¥æ—¥æœŸèˆ‡è³‡æ–™ç‹€æ…‹ã€‚")
        sys.exit(1)
        
    # å°å‡ºæ•¸æ“šåˆ†ä½ˆ
    print_val_stats(df_val, args.tickers)
    
    if args.dry_run:
        print("\nâœ… Dry-Run æ¨¡å¼çµæŸã€‚")
        sys.exit(0)
        
    # 2. æº–å‚™ç‰¹å¾µé™£åˆ— 
    X_val = df_val[FEATURE_COLS].values.astype(np.float32)
    y_val = df_val['y'].values
    
    # 3. è¼‰å…¥æ¨¡å‹ (ä¸ä½¿ç”¨ custom_objectsï¼Œåªå€šé åŸºåº• model_path ä¸­è¨˜è¼‰çš„ç¶²è·¯æ¶æ§‹å³å¯æ¨è«–)
    print("\nğŸ“¦ è¼‰å…¥ PPO æ¨¡å‹...")
    try:
        # å¼·åˆ¶æŒ‡å®š device="cpu" é˜²æ­¢ device map error
        model_ppo = PPO.load(args.model_path, device="cpu")
    except Exception as e:
        print(f"âŒ PPO æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        sys.exit(1)
        
    # 4. æ¨è«–æå–æ©Ÿç‡
    y_proba_val = get_ppo_probabilities(model_ppo, X_val)
    
    # 5. è¨ˆç®—æŒ‡æ¨™
    print("ğŸ“ˆ æ­£åœ¨è¨ˆç®—æŒ‡æ¨™é™£åˆ—...")
    metrics = calc_metrics(y_val, y_proba_val, threshold=args.threshold, prefix="Pooled Overall")
    
    # 6. è¼¸å‡ºå„²å­˜
    # ç”± model æª”åç•¶ä½œè³‡æ–™å¤¾å‰ç¶´
    base_name = os.path.basename(args.model_path).replace(".zip", "")
    run_ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = os.path.join(args.output_dir, f"eval_ppo_{base_name}_{run_ts}")
    os.makedirs(run_dir, exist_ok=True)
    
    # (a) Params Json
    params = {
        "cli_args": vars(args),
        "actual_val_range": val_range,
        "val_samples": len(df_val),
        "val_pos_ratio": float(np.mean(y_val)),
        "eval_model": os.path.abspath(args.model_path),
        "used_threshold": args.threshold
    }
    with open(os.path.join(run_dir, "eval_params.json"), "w", encoding="utf-8") as f:
        json.dump(params, f, indent=4, ensure_ascii=False)
        
    # (b) Metrics Json
    with open(os.path.join(run_dir, "metrics.json"), "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=4, ensure_ascii=False)
        
    # (c) Prediction CSV
    df_val_export = df_val[['date', 'ticker']].copy()
    df_val_export['y_true'] = y_val
    df_val_export['y_proba'] = y_proba_val
    df_val_export['y_pred'] = (y_proba_val >= args.threshold).astype(int)
    df_val_export.to_csv(os.path.join(run_dir, "val_predictions.csv"), index=False)
    
    print("\nâœ… æ¨è«–èˆ‡è©•ä¼°å®Œæˆï¼")
    print("-" * 60)
    print(f"  [Validation Metrics (Pooled / Micro) @ T={args.threshold}]")
    print(f"  Accuracy : {metrics['Accuracy']:.4f}")
    print(f"  ROC-AUC  : {metrics['ROC-AUC']:.4f}" if metrics['ROC-AUC'] else "  ROC-AUC  : N/A")
    print(f"  PR-AUC   : {metrics['PR-AUC']:.4f}" if metrics['PR-AUC'] else "  PR-AUC   : N/A")
    print(f"  Precision: {metrics['Precision']:.4f}")
    print(f"  Recall   : {metrics['Recall']:.4f}")
    print(f"  F1-Score : {metrics['F1']:.4f}")
    print(f"  Precision@5%: {metrics.get('Precision@5%', 0):.4f}")
    print(f"\nğŸ“‚ çµæœå·²å„²å­˜æ–¼: {run_dir}")

if __name__ == "__main__":
    main()
