#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
================================================================================
US Tech Stock - Sklearn Binary Classifier Training Script
================================================================================
Áî®ÊñºË®ìÁ∑¥‰∫åÂàÜÂàÜÈ°ûÊ®°ÂûãÔºåÈ†êÊ∏¨Êú™‰æÜ 20 ÂÄã‰∫§ÊòìÊó•ÂÖßÊòØÂê¶‰∏äÊº≤Ë∂ÖÈÅé 10%„ÄÇ
Â∞áÈáçÁî® train_us_tech_buy_agent.py ÂÖßÁöÑ fetch_all_stock_data Ëàá calculate_features„ÄÇ

ÊîØÊè¥Ê®°Âûã: RandomForest, AdaBoost, HistGradientBoosting
================================================================================
"""

import os
import sys
import json
import joblib
import argparse
from datetime import datetime
import numpy as np
import pandas as pd

from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, 
                             roc_auc_score, average_precision_score, confusion_matrix)
from sklearn.utils.class_weight import compute_class_weight
from sklearn.inspection import permutation_importance

# Â∞áÂ∞àÊ°àÊ†πÁõÆÈåÑÂä†Âà∞ sys.pathÔºå‰ª•‰æø import ÂÖ±Áî®Ê®°ÁµÑ
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

try:
    from train_us_tech_buy_agent import (fetch_all_stock_data, calculate_features, 
                                         FEATURE_COLS, TRAIN_RANGES, VAL_RANGE, BENCHMARK)
except ImportError as e:
    print(f"‚ùå ÁÑ°Ê≥ïÂæû train_us_tech_buy_agent.py ËºâÂÖ•ÂÖ±Áî®ÈÇèËºØ: {e}")
    print("Ë´ãÁ¢∫‰øùËÖ≥Êú¨ÊúâÊîæÁΩÆÂú®Ê≠£Á¢∫ÁöÑÊ†πÁõÆÈåÑ‰∏ãÂ±§ scripts Ë≥áÊñôÂ§æÂÖß„ÄÇ")
    sys.exit(1)


def parse_args():
    parser = argparse.ArgumentParser(description="Train Sklearn binary classifier for Buy Agent (Next 20d Max >= 10%)")
    
    # Ë≥áÊñôÂèÉÊï∏
    parser.add_argument("--tickers", nargs="+", 
                        default=["NVDA", "MSFT", "AAPL", "AMZN", "META", "AVGO", "GOOGL", "TSLA", "NFLX", "PLTR"],
                        help="ÁõÆÊ®ôËÇ°Á•®‰ª£Á¢ºÂàóË°®")
    parser.add_argument("--train-ranges", nargs="*", 
                        help="Ë®ìÁ∑¥Ë≥áÊñôÂçÄÈñì„ÄÇÊ†ºÂºè: YYYY-MM-DD:YYYY-MM-DD (ÂèØÊèê‰æõÂ§öÊÆµÔºåÁ©∫ÁôΩÂàÜÈöî)")
    parser.add_argument("--val-start-date", type=str, help="È©óË≠âÂçÄÈñìËµ∑ÂßãÊó•")
    parser.add_argument("--val-end-date", type=str, help="È©óË≠âÂçÄÈñìÁµêÊùüÊó•")
    
    # Ë®ìÁ∑¥ÂèÉÊï∏
    parser.add_argument("--model", choices=["rf", "adaboost", "hgb"], default="rf",
                        help="ÈÅ∏ÊìáË®ìÁ∑¥Ê®°ÂûãÁ®ÆÈ°û")
    parser.add_argument("--target-days", type=int, default=20, help="È†êÊ∏¨Êú™‰æÜÁöÑ‰∫§ÊòìÂ§©Êï∏ (e.g. 20, 60, 120)")
    parser.add_argument("--target-return", type=float, default=0.10, help="ÁõÆÊ®ôÊúÄÈ´òÂÉπÊº≤ÂπÖÈñÄÊ™ª (e.g. 0.10, 0.20)")
    parser.add_argument("--balance-train", choices=["none", "undersample_50_50", "class_weight_balanced"], 
                        default="none", help="È°ûÂà•‰∏çÂπ≥Ë°°ËôïÁêÜÊñπÂºè (ÂÉÖ‰ΩúÁî®ÊñºË®ìÁ∑¥ÈõÜ)")
    parser.add_argument("--seed", type=int, default=42, help="Èö®Ê©üÁ®ÆÂ≠ê")
    
    # Áí∞Â¢ÉËàáËº∏Âá∫ÂèÉÊï∏
    parser.add_argument("--output-dir", default=os.path.join(ROOT_DIR, "output_sklearn"), 
                        help="Ê®°ÂûãËàáÊåáÊ®ôËº∏Âá∫ÁõÆÈåÑ")
    parser.add_argument("--no-cache", action="store_true", help="ÈóúÈñâÁâπÂæµÂø´Âèñ")
    parser.add_argument("--dry-run", action="store_true", 
                        help="Âè™Ê™¢Êü•Ë≥áÊñôËàáÂàáÂàÜÔºå‰∏çÈÄ≤Ë°åÂØ¶ÈöõË®ìÁ∑¥")
    
    return parser.parse_args()


def get_positive_proba(model, X, positive_label=1) -> tuple:
    """
    ÂèñÂæóÈ†êÊ∏¨ÁÇ∫ positive_label (È†êË®≠ÁÇ∫ 1) ÁöÑÊ©üÁéáÈô£Âàó„ÄÇ
    ÈÅøÂÖç‰æùË≥¥ hard-coded ÁöÑ [:, 1]ÔºåÊîπÁî± model.classes_ ÂãïÊÖãÂ∞ãÊâæ„ÄÇ
    """
    if not hasattr(model, "predict_proba"):
        raise ValueError(f"Ê®°Âûã {type(model).__name__} ‰∏çÊîØÊè¥ predict_proba()")
        
    proba_all = model.predict_proba(X)
    classes = list(model.classes_)
    
    if positive_label not in classes:
        raise ValueError(f"Ê®ôÁ±§ {positive_label} ‰∏çÂ≠òÂú®Êñº model.classes_ {classes} ‰∏≠„ÄÇ")
        
    pos_idx = classes.index(positive_label)
    return proba_all[:, pos_idx], classes, pos_idx


def parse_date_ranges(train_ranges_arg):
    if not train_ranges_arg:
        return TRAIN_RANGES
    parsed = []
    for r in train_ranges_arg:
        parts = r.split(':')
        if len(parts) == 2:
            parsed.append((parts[0], parts[1]))
        else:
            raise ValueError(f"Ë®ìÁ∑¥ÂçÄÈñìÊ†ºÂºèÈåØË™§: {r} (ÊáâÁÇ∫ YYYY-MM-DD:YYYY-MM-DD)")
    return parsed


def prepare_data(args, train_ranges, val_range):
    """
    ËºâÂÖ•‰∏¶ËôïÁêÜË≥áÊñôÔºåËº∏Âá∫Ë®ìÁ∑¥ÈõÜËàáÈ©óË≠âÈõÜ
    """
    all_raw_data = fetch_all_stock_data()
    benchmark_df = all_raw_data.get(BENCHMARK)
    if benchmark_df is None:
        raise ValueError(f"ÁÑ°Ê≥ïËºâÂÖ• benchmark {BENCHMARK} ÁöÑË≥áÊñô„ÄÇ")
        
    use_cache = not args.no_cache
    target_col = f"Next_{args.target_days}d_Max"
    
    train_dfs = []
    val_dfs = []
    
    print(f"\nüîç Ê≠£Âú®ÁîüÊàê/ËºâÂÖ•ÁâπÂæµ... (ÁõÆÊ®ô: {target_col} >= {args.target_return*100:g}%)")
    for ticker in args.tickers:
        if ticker not in all_raw_data:
            print(f"  ‚ö†Ô∏è Êâæ‰∏çÂà∞ {ticker} ÂéüÂßãË≥áÊñôÔºåË∑≥ÈÅé„ÄÇ")
            continue
            
        df_raw = all_raw_data[ticker]
        df_features = calculate_features(df_raw, benchmark_df, ticker=ticker, use_cache=use_cache)
        
        # 1. Á¢∫‰øùÁõÆÊ®ôÊ¨Ñ‰ΩçÂ≠òÂú®‰∏¶ÈÅéÊøæ NaN
        if target_col not in df_features.columns:
            print(f"  ‚ö†Ô∏è Êâæ‰∏çÂà∞ÁâπÂæµÊ¨Ñ‰Ωç {target_col}ÔºåË´ãÁ¢∫ÂÆö calculate_features Â∑≤ÊîØÊè¥Ë©≤Â§©Êï∏„ÄÇ")
            continue
        df_features = df_features.dropna(subset=[target_col])
        
        # 2. Âä†ÂÖ• date Ëàá ticker
        df_features['ticker'] = ticker
        df_features['date'] = df_features.index.strftime('%Y-%m-%d')
        
        # 3. Âª∫Á´ãÊ®ôÁ±§ y
        df_features['y'] = (df_features[target_col] >= args.target_return).astype(int)
        
        # 4. ÊôÇÈñìÂàáÂàÜ (Walk-forward Split)
        # Ë®ìÁ∑¥ÈõÜ
        train_mask = pd.Series(False, index=df_features.index)
        for start, end in train_ranges:
            train_mask |= (df_features.index >= pd.Timestamp(start)) & (df_features.index <= pd.Timestamp(end))
        df_train_tick = df_features[train_mask]
        
        # È©óË≠âÈõÜ
        val_start, val_end = val_range
        val_mask = (df_features.index >= pd.Timestamp(val_start)) & (df_features.index <= pd.Timestamp(val_end))
        df_val_tick = df_features[val_mask]
        
        train_dfs.append(df_train_tick)
        val_dfs.append(df_val_tick)
        
    df_train = pd.concat(train_dfs, ignore_index=True) if train_dfs else pd.DataFrame()
    df_val = pd.concat(val_dfs, ignore_index=True) if val_dfs else pd.DataFrame()
    
    return df_train, df_val


def print_data_stats(df_train, df_val, tickers):
    """Âç∞Âá∫Ë≥áÊñôÈõÜÁµ±Ë®àË≥áË®ä"""
    print("\nüìä Ë≥áÊñôÂàáÂàÜËàáÈ°ûÂà•ÊØî‰æãÁµ±Ë®à")
    print("-" * 60)
    print(f"{'Ticker':<8} | {'Train (N)':<10} | {'Train Pos%':<10} | {'Val (N)':<10} | {'Val Pos%':<10}")
    print("-" * 60)
    
    for tk in tickers:
        d_tr = df_train[df_train['ticker'] == tk]
        d_va = df_val[df_val['ticker'] == tk]
        tr_len = len(d_tr)
        va_len = len(d_va)
        tr_pos = d_tr['y'].mean() if tr_len > 0 else 0
        va_pos = d_va['y'].mean() if va_len > 0 else 0
        print(f"{tk:<8} | {tr_len:<10} | {tr_pos*100:6.2f}%    | {va_len:<10} | {va_pos*100:6.2f}%")
        
    print("-" * 60)
    tot_tr_len = len(df_train)
    tot_va_len = len(df_val)
    tot_tr_pos = df_train['y'].mean() if tot_tr_len > 0 else 0
    tot_va_pos = df_val['y'].mean() if tot_va_len > 0 else 0
    print(f"{'TOTAL':<8} | {tot_tr_len:<10} | {tot_tr_pos*100:6.2f}%    | {tot_va_len:<10} | {tot_va_pos*100:6.2f}%")
    print("-" * 60)


def apply_class_balancing(df_train, balance_method, seed):
    """Ê†πÊìö balance_method ËôïÁêÜË®ìÁ∑¥ÈõÜÁöÑ Class Imbalance"""
    if balance_method == 'undersample_50_50':
        pos_df = df_train[df_train['y'] == 1]
        neg_df = df_train[df_train['y'] == 0]
        min_len = min(len(pos_df), len(neg_df))
        if min_len == 0:
            return df_train
            
        pos_sample = pos_df.sample(n=min_len, random_state=seed)
        neg_sample = neg_df.sample(n=min_len, random_state=seed)
        
        # Á¢∫‰øùÈ†ÜÂ∫è‰∏çË¢´Êâì‰∫ÇÊàñËÄÖÈáçÊéí
        balanced_df = pd.concat([pos_sample, neg_sample]).sort_index()
        print(f"\n‚öñÔ∏è  [Undersample 50/50] ÈáçÊñ∞ÂèñÊ®£Âæå Train Size: {len(balanced_df)} (Pos: {len(pos_sample)}, Neg: {len(neg_sample)})")
        return balanced_df
        
    return df_train


def get_model(model_name, balance_method, seed):
    """ÂõûÂÇ≥ÊåáÂÆöÊ®°ÂûãËàáÊòØÂê¶ÈúÄË¶ÅÂú® fit() ‰∏≠‰ΩøÁî® sample_weight"""
    class_weight = 'balanced' if balance_method == 'class_weight_balanced' else None
    
    if model_name == 'rf':
        model = RandomForestClassifier(n_estimators=100, max_depth=10, 
                                       random_state=seed, class_weight=class_weight, n_jobs=-1)
        return model, False # RF built-in handles class_weight

    elif model_name == 'adaboost':
        # DecisionTreeClassifier ÊîØÊè¥ class_weight
        base = DecisionTreeClassifier(max_depth=2, class_weight=class_weight, random_state=seed)
        model = AdaBoostClassifier(estimator=base, n_estimators=100, random_state=seed)
        return model, False

    elif model_name == 'hgb':
        # HistGradientBoostingClassifier ÈõñÁÑ∂‰∏çÁõ¥Êé•ÊîØÊè¥ class_weight='balanced'
        # Âú® sklearn ‰∏≠ÂèØ‰ª•ÊîπÁî± class_weight parameter (Âú® 1.3+) ÊàñÊòØ‰ΩøÁî® fit ÂÇ≥ÈÅû sample_weight
        try:
            model = HistGradientBoostingClassifier(max_iter=100, max_depth=10, 
                                                   random_state=seed, class_weight=class_weight)
            return model, False
        except TypeError:
            # Fallback for older scikit-learn versions
            model = HistGradientBoostingClassifier(max_iter=100, max_depth=10, random_state=seed)
            return model, (class_weight == 'balanced')
            
    else:
        raise ValueError(f"‰∏çÊîØÊè¥ÁöÑÊ®°ÂûãÁ®ÆÈ°û: {model_name}")


def calc_metrics(y_true, y_proba, y_pred, prefix="Overall"):
    """Ë®àÁÆó‰∏¶ÂõûÂÇ≥È©óË≠âÈõÜÁöÑÂêÑÁ®ÆÊåáÊ®ô"""
    metrics = {}
    
    # ÈÅøÂÖç y_true ÂÖ® 0 ÊàñÂÖ® 1 Â∞éËá¥ auc Â§±Êïó
    has_mixed_classes = len(np.unique(y_true)) > 1
    
    metrics['Accuracy'] = float(accuracy_score(y_true, y_pred))
    metrics['Precision'] = float(precision_score(y_true, y_pred, zero_division=0))
    metrics['Recall'] = float(recall_score(y_true, y_pred, zero_division=0))
    metrics['F1'] = float(f1_score(y_true, y_pred, zero_division=0))
    
    metrics['ROC-AUC'] = float(roc_auc_score(y_true, y_proba)) if has_mixed_classes else None
    metrics['PR-AUC'] = float(average_precision_score(y_true, y_proba)) if has_mixed_classes else None
    
    metrics['Confusion Matrix'] = confusion_matrix(y_true, y_pred).tolist()
    
    # Precision@k (Top 1%, 5%, 10%)
    sort_idx = np.argsort(y_proba)[::-1]
    sorted_y_true = np.array(y_true)[sort_idx]
    
    for k_pct in [0.01, 0.05, 0.10]:
        k = max(1, int(len(y_true) * k_pct))
        top_k_y_true = sorted_y_true[:k]
        metrics[f'Precision@{int(k_pct*100)}%'] = float(np.mean(top_k_y_true))
        
    # Threshold sweep
    metrics['Threshold Sweep'] = {}
    for th in [0.5, 0.6, 0.7, 0.8, 0.9]:
        y_pred_th = (y_proba >= th).astype(int)
        metrics['Threshold Sweep'][f'Threshold={th}'] = {
            'Precision': float(precision_score(y_true, y_pred_th, zero_division=0)),
            'Recall': float(recall_score(y_true, y_pred_th, zero_division=0)),
            'F1': float(f1_score(y_true, y_pred_th, zero_division=0))
        }
        
    return metrics


def get_feature_importances(model, model_name, X_val, y_val):
    """Ë®àÁÆó‰∏¶ÂõûÂÇ≥ÁâπÂæµÈáçË¶ÅÊÄß"""
    importances_dict = {}
    print("\nüîç Ê≠£Âú®Ë®àÁÆó Feature Importances (Top 30)...")
    
    if model_name == 'rf':
        try:
            importances = model.feature_importances_
            indices = np.argsort(importances)[::-1]
            for i in indices[:30]:
                importances_dict[FEATURE_COLS[i]] = float(importances[i])
        except AttributeError:
            pass
    
    # Â∞çÂÖ∂‰ªñÊ®°Âûã‰ΩøÁî® permutation importance (ÈáùÂ∞ç Validation Subset ÂèñÊ®£‰ª•Ê±ÇÊïàÁéá)
    if not importances_dict:
        n_samples = min(50000, len(X_val))
        idx = np.random.choice(len(X_val), n_samples, replace=False)
        X_sub = X_val.iloc[idx]
        y_sub = y_val.iloc[idx]
        
        result = permutation_importance(model, X_sub, y_sub, n_repeats=5, random_state=42, n_jobs=-1)
        importances = result.importances_mean
        indices = np.argsort(importances)[::-1]
        
        for i in indices[:30]:
            importances_dict[FEATURE_COLS[i]] = float(importances[i])
            
    return importances_dict


def main():
    args = parse_args()
    
    # Ê±∫ÂÆöÂàáÂâ≤ÂçÄÊÆµ
    train_ranges = parse_date_ranges(args.train_ranges)
    val_range = (
        args.val_start_date if args.val_start_date else VAL_RANGE[0],
        args.val_end_date if args.val_end_date else VAL_RANGE[1]
    )
    
    print("=" * 60)
    print("üöÄ Sklearn Binary Classifier Training")
    print("=" * 60)
    print(f"  Model       : {args.model}")
    print(f"  Target      : Next_{args.target_days}d_Max >= {args.target_return*100:g}%")
    print(f"  Tickers     : {', '.join(args.tickers)}")
    print(f"  Train Ranges: {train_ranges}")
    print(f"  Val Range   : {val_range}")
    print(f"  Balance Mode: {args.balance_train}")
    print(f"  Dry Run     : {args.dry_run}")
    print("=" * 60)
    
    # 1. Ê∫ñÂÇôË≥áÊñô
    df_train, df_val = prepare_data(args, train_ranges, val_range)
    
    if len(df_train) == 0 or len(df_val) == 0:
        print("‚ùå Ë®ìÁ∑¥ÊàñÈ©óË≠âË≥áÊñôÈõÜÁÇ∫Á©∫ÔºåË´ãÊ™¢Êü•Êó•ÊúüËàáË≥áÊñô‰∏ãËºâÁãÄÊÖã„ÄÇ")
        sys.exit(1)
        
    # Âç∞Âá∫È†êË®≠Áµ±Ë®àÂàÜÂ∏É
    print_data_stats(df_train, df_val, args.tickers)
    
    # Â¶ÇÊûúÊòØ Dry-run Â∞±Áõ¥Êé•ÁµêÊùü
    if args.dry_run:
        print("\n‚úÖ Dry-Run Ê®°ÂºèÁµêÊùü„ÄÇ")
        sys.exit(0)
    
    # 2. È°ûÂà•Âπ≥Ë°° (ÂÉÖÂú®Ë®ìÁ∑¥ÈöéÊÆµËôïÁêÜ)
    df_train_b = apply_class_balancing(df_train, args.balance_train, args.seed)
    
    X_train = df_train_b[FEATURE_COLS]
    y_train = df_train_b['y']
    
    X_val = df_val[FEATURE_COLS]
    y_val = df_val['y']
    
    # 3. Ê∫ñÂÇôÊ®°Âûã
    model, needs_sample_weight = get_model(args.model, args.balance_train, args.seed)
    
    sample_weight = None
    if needs_sample_weight:
        cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
        w_dict = dict(zip(np.unique(y_train), cw))
        sample_weight = np.array([w_dict[y] for y in y_train])
        
    print(f"\n‚öôÔ∏è  ÈñãÂßãË®ìÁ∑¥ {args.model.upper()} ...")
    if sample_weight is not None:
        model.fit(X_train, y_train, sample_weight=sample_weight)
    else:
        model.fit(X_train, y_train)
        
    # 4. È†êÊ∏¨ËàáË®àÁÆóÊåáÊ®ô
    print("üìà Ê≠£Âú®Â∞ç Validation Subset ÈÄ≤Ë°åË©ï‰º∞...")
    try:
        y_proba_val, clz_list, pos_idx = get_positive_proba(model, X_val, positive_label=1)
    except Exception as e:
        print(f"‚ùå ÂèñÂæóÈ†êÊ∏¨Ê©üÁéáÂ§±Êïó: {e}")
        sys.exit(1)
        
    y_pred_val = model.predict(X_val)
    
    # Ë®àÁÆóÊ≠£Ë≤†Ê®£Êú¨ÁöÑÂπ≥ÂùáÊ©üÁéá (Sanity Check)
    mask_pos = (y_val == 1)
    mask_neg = (y_val == 0)
    mean_pos_proba = y_proba_val[mask_pos].mean() if mask_pos.sum() > 0 else 0.0
    mean_neg_proba = y_proba_val[mask_neg].mean() if mask_neg.sum() > 0 else 0.0
    
    proba_direction_warning = False
    if mean_pos_proba < mean_neg_proba:
        print(f"  ‚ö†Ô∏è [WARNING] Ê≠£Ê®£Êú¨ÁöÑÂπ≥ÂùáÈ†êÊ∏¨Ê©üÁéá ({mean_pos_proba:.4f}) Â∞èÊñº Ë≤†Ê®£Êú¨ ({mean_neg_proba:.4f})ÔºÅ")
        print("     ÈÄôÂèØËÉΩÊöóÁ§∫ÂàÜÈ°ûÂô®ÁöÑÂ≠∏ÁøíÁµêÊûúÊñπÂêëÁõ∏ÂèçÔºåÊàñÊ≠£È°ûË¢´ÈåØË™§Â∞çÊáâ„ÄÇROC-AUC ÂèØËÉΩ < 0.5„ÄÇ")
        proba_direction_warning = True
    
    metrics = calc_metrics(y_val, y_proba_val, y_pred_val, prefix="Pooled Overall")
    metrics['Sanity Check'] = {
        'mean_pos_proba': float(mean_pos_proba),
        'mean_neg_proba': float(mean_neg_proba),
        'proba_direction_warning': proba_direction_warning
    }
    
    # Ë®àÁÆó Feature Importances
    importances = get_feature_importances(model, args.model, X_val, y_val)
    metrics['Feature Importances'] = importances
    
    # 5. Ëº∏Âá∫ÂÑ≤Â≠ò
    run_ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = os.path.join(args.output_dir, f"run_{args.model}_{args.target_days}d_{run_ts}")
    os.makedirs(run_dir, exist_ok=True)
    
    # (a) Model joblib
    joblib.dump(model, os.path.join(run_dir, "model.joblib"))
    
    # (b) Params Json
    params = {
        "cli_args": vars(args),
        "target_definition": f"Next_{args.target_days}d_Max >= {args.target_return}",
        "actual_train_ranges": train_ranges,
        "actual_val_range": val_range,
        "train_samples_raw": len(df_train),
        "train_samples_balanced": len(df_train_b),
        "val_samples": len(df_val),
        "impl_details": {
            "balance_application": "sample_weight passed to fit" if sample_weight is not None else ("class_weight arg passed" if args.balance_train == "class_weight_balanced" else args.balance_train),
            "model_classes": [int(c) for c in clz_list],
            "positive_class_index": int(pos_idx)
        }
    }
    with open(os.path.join(run_dir, "params.json"), "w", encoding="utf-8") as f:
        json.dump(params, f, indent=4, ensure_ascii=False)
        
    # (c) Metrics Json
    with open(os.path.join(run_dir, "metrics.json"), "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=4, ensure_ascii=False)
        
    # (d) Prediction CSV
    df_val_export = df_val[['date', 'ticker']].copy()
    df_val_export['y_true'] = y_val
    df_val_export['y_proba'] = y_proba_val
    df_val_export['y_pred'] = y_pred_val
    df_val_export.to_csv(os.path.join(run_dir, "val_predictions.csv"), index=False)
    
    print("\n‚úÖ Ë®ìÁ∑¥ÂÆåÊàêÔºÅ")
    print("-" * 60)
    print(f"  [Validation Metrics (Pooled / Micro)]")
    print(f"  Accuracy : {metrics['Accuracy']:.4f}")
    print(f"  ROC-AUC  : {metrics['ROC-AUC']:.4f}" if metrics['ROC-AUC'] else "  ROC-AUC  : N/A")
    print(f"  PR-AUC   : {metrics['PR-AUC']:.4f}" if metrics['PR-AUC'] else "  PR-AUC   : N/A")
    print(f"  Precision: {metrics['Precision']:.4f}")
    print(f"  Recall   : {metrics['Recall']:.4f}")
    print(f"  F1-Score : {metrics['F1']:.4f}")
    print(f"\nüìÇ ÁµêÊûúÂ∑≤ÂÑ≤Â≠òÊñº: {run_dir}")

if __name__ == "__main__":
    main()
