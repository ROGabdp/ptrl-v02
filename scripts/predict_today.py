#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
================================================================================
US Tech Stock - Daily Train & Predictor
================================================================================
é€™å€‹è…³æœ¬ç”¨ä¾†å¹«åŠ©æ‚¨æ¯å¤©è¼‰å…¥æœ€æ–°çš„è‚¡ç¥¨è³‡æ–™ï¼Œé€²è¡Œè‡ªå‹•åŒ–ç•¶æ—¥å»ºæ¨¡ (Daily Train) 
ä¸¦æ¨æ–·ã€Œä»Šæ—¥æœ€æ–°çš„æ”¶ç›¤æ•¸å€¼ã€æ˜¯å¦æ»¿è¶³æœªä¾†æ¼²å¹…çš„è²·é»ç‰¹å¾µï¼Œä¸¦ç”¢å‡º Top K æ¨è–¦æ¸…å–®ã€‚

å¦‚æœæä¾› --model-pathï¼Œå‰‡æœƒé€€å›å‚³çµ±æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨æå‰é å…ˆè¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œæ¨è«–ã€‚
================================================================================
"""

import os
import sys
import argparse
import joblib
import pandas as pd
import numpy as np
import warnings
from datetime import datetime, timedelta

warnings.filterwarnings('ignore', category=UserWarning)

ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

from src.train.sklearn_utils import get_positive_proba
from src.features.regime_features import compute_regime_features, REGIME_COLS

try:
    from train_us_tech_buy_agent import fetch_all_stock_data, calculate_features, FEATURE_COLS, BENCHMARK
except ImportError as e:
    print(f"âŒ ç„¡æ³•å¾ train_us_tech_buy_agent.py è¼‰å…¥å…±ç”¨é‚è¼¯: {e}")
    sys.exit(1)


def parse_args():
    parser = argparse.ArgumentParser(description="Predict 'Today's Buy Decision' for US Tech Stocks")
    
    # åŸ·è¡Œæ¨¡å¼ (Daily Train æˆ–æ˜¯ å‚³çµ±è®€å–æ¨¡å¼)
    parser.add_argument("--model-path", type=str, default=None, 
                        help="é¸å¡«ï¼šæä¾›å·²è¨“ç·´æ¨¡å‹è·¯å¾‘ (.zip/.joblib)ã€‚è‹¥æœªæä¾›ï¼Œå‰‡å•Ÿå‹• Daily Train æ¨¡å¼è‡ªå‹•å»ºæ§‹ç•¶æ—¥æ¨¡å‹ã€‚")
    
    # ç›®æ¨™è¨­å®š
    parser.add_argument("--tickers", nargs="+", 
                        default=["NVDA", "MSFT", "AAPL", "AMZN", "META", "AVGO", "GOOGL", "TSLA", "NFLX", "PLTR"],
                        help="è¦é æ¸¬çš„ç›®æ¨™è‚¡ç¥¨åˆ—è¡¨ (é è¨­ 10 æª”)")
    parser.add_argument("--target-days", type=int, default=120, help="é æ¸¬æœªä¾†çš„äº¤æ˜“å¤©æ•¸ (é è¨­ 120)")
    parser.add_argument("--target-return", type=float, default=0.20, help="ç›®æ¨™æœ€é«˜åƒ¹æ¼²å¹…é–€æª» (é è¨­ 0.20)")
    
    # Daily Train åƒæ•¸
    parser.add_argument("--window-years", type=int, default=3, help="Daily Train æŠ“å–çš„æ­·å²è¨“ç·´çª—æ ¼å¤§å° (é è¨­ 3 å¹´)")
    parser.add_argument("--use-regime-features", type=str, default="true", choices=["true", "false"], 
                        help="æ˜¯å¦æ›è¼‰å¤§ç›¤ Regime Features ä¸€ä½µè¨“ç·´/é æ¸¬ (é è¨­ true)")
    parser.add_argument("--force-retrain", action="store_true", help="å¼·åˆ¶é‡æ–°è¨“ç·´æ–°æ¨¡å‹ï¼Œå³ä½¿ä»Šæ—¥å·²å­˜åœ¨å¿«å–")
    parser.add_argument("--output-dir", type=str, default="output_daily", help="ç•¶æ—¥æ¨¡å‹å„²å­˜æ ¹ç›®éŒ„")
    parser.add_argument("--no-cache", action="store_true", help="å¼·åˆ¶é‡æ–°è¨ˆç®—ç‰¹å¾µè€Œä¸æ˜¯è®€å–æ˜¨å¤©å¿«å–")
    
    # æ±ºç­–è¼¸å‡ºåƒæ•¸
    parser.add_argument("--topk-pct", type=int, default=10, help="Top K è¼¸å‡ºçš„ç™¾åˆ†æ¯” (é è¨­ 10%)")
    parser.add_argument("--topk-n", type=int, default=None, help="çµ•å°æ•¸å€¼çš„ Top Kï¼Œè‹¥æä¾›å‰‡å„ªå…ˆæ–¼ pct")
    parser.add_argument("--threshold", type=float, default=0.5, help="(å‚³çµ±æ¨¡å¼ç”¨) æ±ºå®šè²·é€²çš„æ­£é¡æ©Ÿç‡é–¾å€¼ (é è¨­ 0.5)")
    return parser.parse_args()


def load_model_and_predict(model_path, model_type, X_input):
    if model_type == "ppo":
        from stable_baselines3 import PPO
        import torch
        model = PPO.load(model_path, device="cpu")
        with torch.no_grad():
            obs_tensor = torch.tensor(X_input, dtype=torch.float32, device="cpu")
            distribution = model.policy.get_distribution(obs_tensor)
            proba = distribution.distribution.probs[:, 1].cpu().numpy()[0]
        return proba
        
    elif model_type in ["sklearn", "daily"]:
        model = joblib.load(model_path)
        # ç”¨ pandas å¡é€²å»é¿å… warn (è‹¥æœ‰ col names)
        # è‹¥å‚³é€²ä¾†æ˜¯ np array çš„ X_input ä¹Ÿæœƒç›´æ¥å°ä»˜
        y_proba, _, _ = get_positive_proba(model, pd.DataFrame(X_input), positive_label=1)
        return float(y_proba[0])
        
    else:
        raise ValueError(f"ä¸èªå¾—çš„æ¨¡å‹æ ¼å¼: {model_type}")

def fetch_and_prepare_daily_data(args):
    # ä¸‹è¼‰æ¨å¾€å‰æ¨ 8 å¹´çš„è³‡æ–™ä»¥ä¿ç•™è¶³å¤  Buffer (MA240 + window_years)
    start_date = (datetime.today() - timedelta(days=8*365)).strftime("%Y-%m-%d")
    print(f"ğŸ“¥ æ­£åœ¨å¾ Yahoo Finance ç²å–/æ›´æ–°æœ€æ–°è‚¡åƒ¹ (è‡ª {start_date} èµ·)...")
    
    all_data = fetch_all_stock_data(start_date=start_date)
    benchmark_df = all_data.get(BENCHMARK)
    
    if benchmark_df is None:
        raise ValueError(f"âŒ ç„¡æ³•è¼‰å…¥åŸºæº–æŒ‡æ•¸ {BENCHMARK} çš„è³‡æ–™ã€‚")
        
    return all_data, benchmark_df

def train_daily_model(args, all_data, benchmark_df):
    """å°‡å„ Tickers çš„ç‰¹å¾µä¸²æ¥åœ¨ä¸€èµ·ï¼Œå»ºç«‹ä¸€ä»½ç•¶æ—¥çµ±æ•´æ¨¡å‹"""
    today_str = datetime.today().strftime("%Y%m%d")
    daily_model_dir = os.path.join(args.output_dir, today_str)
    os.makedirs(daily_model_dir, exist_ok=True)
    
    model_save_path = os.path.join(daily_model_dir, "model.joblib")
    
    use_regime = (args.use_regime_features == "true")
    active_cols = FEATURE_COLS + (REGIME_COLS if use_regime else [])
    
    if os.path.exists(model_save_path) and not args.force_retrain:
        print(f"â™»ï¸ ç™¼ç¾ä»Šæ—¥å¿«å–æ¨¡å‹ï¼Œç›´æ¥è¼‰å…¥: {model_save_path}")
        return model_save_path, active_cols, ("Loaded from cache", "Loaded from cache")
        
    print(f"âš™ï¸ æº–å‚™ Daily Train è¨“ç·´è³‡æ–™é›† (Window: {args.window_years} years)...")
    
    train_dfs = []
    regime_df = compute_regime_features(benchmark_df) if use_regime else None
    
    # æ±ºå®šè¨“ç·´åˆ‡å‰²é‚Šç•Œ: ç¢ºä¿ y label ä¸æ¼çœ‹æœªä¾†
    # å–å…¨éƒ¨è‚¡ç¥¨æœ€æ–°çš„ä¸€å¤©ä½œç‚º T
    latest_date_overall = None
    for tk in args.tickers:
        if tk in all_data and len(all_data[tk]) > 0:
            last_dt = all_data[tk].index[-1] if isinstance(all_data[tk].index, pd.DatetimeIndex) else pd.to_datetime(all_data[tk]['Date']).max()
            if latest_date_overall is None or last_dt > latest_date_overall:
                latest_date_overall = last_dt
                
    if latest_date_overall is None:
        latest_date_overall = pd.to_datetime(datetime.today())
        
    train_end = latest_date_overall
    train_start = train_end - pd.DateOffset(years=args.window_years)
    
    train_start_str = train_start.strftime("%Y-%m-%d")
    train_end_str = train_end.strftime("%Y-%m-%d")
    print(f"  [Train Window Range] {train_start_str} ~ {train_end_str}")
    
    target_col = f"Next_{args.target_days}d_Max"
    
    for tk in args.tickers:
        raw_df = all_data.get(tk)
        if raw_df is None or len(raw_df) == 0: continue
            
        feat_df = calculate_features(raw_df, benchmark_df, ticker=tk, use_cache=not args.no_cache)
        if target_col not in feat_df.columns:
            continue
            
        feat_df = feat_df.reset_index()
        if 'Date' in feat_df.columns:
            feat_df.rename(columns={'Date': 'date'}, inplace=True)
        elif 'index' in feat_df.columns:
            feat_df.rename(columns={'index': 'date'}, inplace=True)
            
        feat_df['date'] = pd.to_datetime(feat_df['date'])
        
        # Merge regime
        if use_regime:
            feat_df['date_str'] = feat_df['date'].dt.strftime('%Y-%m-%d')
            # regime_df çš„ date ä¹Ÿæ˜¯å­—ä¸²
            feat_df = pd.merge(feat_df, regime_df, left_on='date_str', right_on='date', how='inner', suffixes=('', '_regime'))
            
        # åˆ‡å‰²è¨“ç·´é›†
        mask = (feat_df['date'] >= train_start) & (feat_df['date'] <= train_end)
        train_slice = feat_df[mask].copy()
        train_slice = train_slice.dropna(subset=active_cols + [target_col])
        
        train_slice['y'] = (train_slice[target_col] >= args.target_return).astype(int)
        train_dfs.append(train_slice)
        
    if not train_dfs:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•æœ‰æ•ˆçš„è¨“ç·´è³‡æ–™ï¼Œè«‹æª¢æŸ¥å€é–“æˆ– Tickers è¨­å®š")
        sys.exit(1)
        
    df_train_pooled = pd.concat(train_dfs, ignore_index=True)
    X_train = df_train_pooled[active_cols]
    y_train = df_train_pooled['y']
    
    print(f"ğŸ§  é€²è¡Œ HistGradientBoosting æ¨¡å‹é›†è¨“ (N={len(X_train)}, Pos Rate={y_train.mean()*100:.2f}%) ...")
    from sklearn.ensemble import HistGradientBoostingClassifier
    model = HistGradientBoostingClassifier(random_state=42)
    model.fit(X_train, y_train)
    
    joblib.dump(model, model_save_path)
    print(f"âœ… ç•¶æ—¥æ¨¡å‹å„²å­˜å®Œç•¢: {model_save_path}")
    
    return model_save_path, active_cols, (train_start_str, train_end_str)

def evaluate_regime_risk(benchmark_df):
    """åˆ¤æ–·å¸‚å ´æ˜¯å¦è™•æ–¼é«˜é¢¨éšªç‹€æ…‹ (V2 Proxy é¢¨æ§æ©Ÿåˆ¶)"""
    regime_df = compute_regime_features(benchmark_df)
    if len(regime_df) == 0: return "NORMAL", False
    
    latest_regime = regime_df.iloc[-1]
    
    bm_above_ma200 = latest_regime.get('REGIME_BM_ABOVE_MA200', 1.0)
    hv20_pctl = latest_regime.get('REGIME_BM_HV20_PCTL', 0.0)
    ret_120 = latest_regime.get('REGIME_BM_RET_120', 0.0)
    
    is_risk = False
    reason = []
    
    if bm_above_ma200 == 0 and hv20_pctl > 0.8:
        is_risk = True
        reason.append(" MA200 Below & HV20 Pctl > 80% ")
        
    if ret_120 < 0 and hv20_pctl > 0.8:
        is_risk = True
        reason.append(" 120d Return < 0 & HV20 Pctl > 80% ")
        
    if is_risk:
        return f"HIGH RISK (Proxy: {'|'.join(reason)})", True
    return "NORMAL", False
    

def main():
    args = parse_args()
    
    is_daily_train = (args.model_path is None)
    
    print("====================================================================")
    print("ğŸš€ US Tech Stock - Daily Train & Predictor")
    print("====================================================================")
    print(f"  Mode        : {'Daily Train & Predict' if is_daily_train else 'Legacy Predict (Loaded Model)'}")
    print(f"  Target      : Next_{args.target_days}d_Max >= {args.target_return*100:g}%")
    print(f"  Tickers     : {', '.join(args.tickers)}")
    if not is_daily_train:
        print(f"  Threshold   : {args.threshold} (Legacy Mode)")
    print("====================================================================\n")
    
    try:
         all_data, benchmark_df = fetch_and_prepare_daily_data(args)
    except Exception as e:
         print(f"âŒ {e}")
         sys.exit(1)
         
    # --- æ¨¡å‹è™•ç†èˆ‡å‰ç½®ä½œæ¥­ ---
    active_cols = FEATURE_COLS
    train_range = ("N/A", "N/A")
    use_regime_features = False
    
    if is_daily_train:
         use_regime_features = (args.use_regime_features == "true")
         model_path, active_cols, train_range = train_daily_model(args, all_data, benchmark_df)
         model_type = "daily"
    else:
         multi_model = "{ticker}" in args.model_path
         model_ext = ".zip" if ".zip" in args.model_path else ".joblib"
         model_type = "ppo" if model_ext == ".zip" else "sklearn"
         model_path = args.model_path
         
    # --- Regime é¢¨éšªæ¨æ–· ---
    risk_status_text, is_high_risk = evaluate_regime_risk(benchmark_df)
    
    
    # --- é€ Ticker èƒå–ä»Šæ—¥ç‰¹å¾µèˆ‡æ¨è«– ---
    results = [] # (ticker, latest_date, proba, warning_text)
    
    regime_df = compute_regime_features(benchmark_df) if use_regime_features else None
    
    for ticker in args.tickers:
        raw_df = all_data.get(ticker)
        if raw_df is None or len(raw_df) == 0: continue
        
        cur_model_path = model_path.replace("{ticker}", ticker) if not is_daily_train and "{ticker}" in model_path else model_path
        if not os.path.exists(cur_model_path):
             results.append((ticker, "N/A", -1.0, "No Model"))
             continue
             
        try:
             feat_df = calculate_features(raw_df, benchmark_df, ticker=ticker, use_cache=not args.no_cache)
             latest_feat = feat_df.iloc[-1:].copy()
             
             if 'Date' in latest_feat.columns:
                 latest_date = latest_feat['Date'].iloc[0].strftime("%Y-%m-%d")
             elif latest_feat.index.name == 'Date' or isinstance(latest_feat.index, pd.DatetimeIndex):
                 latest_date = latest_feat.index[0].strftime("%Y-%m-%d")
             else:
                 latest_date = "Unknown"
                 
             if use_regime_features:
                 # å–å› regime æœ€å¾Œä¸€ç­† (å› ç‚ºæ˜¯å¤§ç›¤ï¼Œä¸ä¸€å®šå°é½Šï¼Œå–å°æ‡‰æ—¥æœŸ)
                 matching_regime = regime_df.loc[regime_df['date'] == latest_date]
                 if matching_regime.empty:
                      # å‡å¦‚å°ä¸åˆ°æ—¥æœŸï¼Œé€€è€Œæ±‚å…¶æ¬¡æŠ“å¤§ç›¤æœ€å¾Œä¸€ç­†
                      latest_regime_row = regime_df.iloc[-1]
                 else:
                      latest_regime_row = matching_regime.iloc[0]
                      
                 for c in REGIME_COLS:
                      latest_feat[c] = latest_regime_row[c]
                      
             # å–å€¼é æ¸¬ï¼Œå°‡ DataFrame åŒ…è£å¡å…¥ä»¥ä¿ç•™ pandas column åå­—
             X_input = pd.DataFrame([latest_feat[active_cols].iloc[0]], columns=active_cols)
             if model_type == "ppo": X_input = X_input.values.astype(np.float32)
             
             proba = load_model_and_predict(cur_model_path, model_type, X_input)
             results.append((ticker, latest_date, proba, ""))
             
        except Exception as e:
             results.append((ticker, "N/A", -1.0, f"Error: {str(e)[:15]}"))
             
             
    # --- æ±ºç­–é‚è¼¯ (Top K) ---
    if is_daily_train:
         # è¨ˆç®—åé¡
         total_valid = len([r for r in results if r[2] >= 0])
         if args.topk_n is not None:
              base_k = args.topk_n
         else:
              base_k = max(1, int(total_valid * (args.topk_pct / 100.0)))
              
         final_k = base_k
         if is_high_risk:
              final_k = max(0, base_k // 2)
              
         # æ’åº
         results.sort(key=lambda x: x[2], reverse=True)
         
         final_rows = []
         rank = 1
         for tk, dt, pb, warn in results:
             if pb < 0:
                 action = warn
             else:
                 if is_high_risk and final_k == 0:
                      action = "SKIP_RISK ğŸ›‘"
                 elif rank <= final_k:
                      action = "BUY_TOPK ğŸŸ¢"
                 elif rank <= base_k and is_high_risk:
                      action = "DOWNGRADE_RISK âš ï¸"
                 else:
                      action = "WATCHLIST âšª"
                 rank += 1
             final_rows.append((tk, dt, pb, action))
             
    else:
         # Legacy Threshold mode
         final_rows = []
         for tk, dt, pb, warn in results:
             if pb < 0: action = warn
             else:
                 action = "BUY ğŸŸ¢" if pb >= args.threshold else "WAIT âšª"
             final_rows.append((tk, dt, pb, action))
             

    # --- å ±è¡¨è¼¸å‡º ---
    print("\nğŸ“Š ä»Šæ—¥æ¨è«–çµæœ (Prediction for Latest Close)")
    print("-" * 75)
    header_prob = f"Score P({args.target_days})"
    print(f"{'Rank':<5} | {'Ticker':<8} | {'Latest Date':<12} | {header_prob:<14} | {'Action':<15}")
    print("-" * 75)
    
    r_idx = 1
    for tk, dt, pb, act in final_rows:
        pb_str = "N/A" if (pb < 0 or np.isnan(pb)) else f"{pb*100:6.2f}%"
        rank_str = f"#{r_idx}" if pb >= 0 else "-"
        print(f"{rank_str:<5} | {tk:<8} | {dt:<12} | {pb_str:<14} | {act:<15}")
        if pb >= 0: r_idx += 1
        
    print("-" * 75)
    print("ğŸ“ ã€å ±è¡¨ç¸½çµã€‘")
    if is_daily_train:
         print(f"  [æ¨¡å‹çª—æ ¼] {train_range[0]} ~ {train_range[1]} (3y Pooled HGB) {'å« Regime ç‰¹å¾µ' if use_regime_features else ''}")
         print(f"  [é¢¨æ§ç‹€æ…‹] {risk_status_text}")
         
         topk_desc = f"{args.topk_n} æª”" if args.topk_n else f"{args.topk_pct}%"
         if is_high_risk:
              print(f"  [å‡ºæ‰‹ç­–ç•¥] åŸç›®æ¨™ Top {topk_desc} (é™æ§“æ¡¿ç¸®å€‰: å– {final_k} æª”)")
         else:
              print(f"  [å‡ºæ‰‹ç­–ç•¥] å– Top {topk_desc} (ç™¼æ”¾åé¡: {final_k} æª”)")
         print(f"  [å¿«å–è·¯å¾‘] {model_path}")
    else:
         print(f"  [æ¨¡å‹è·¯å¾‘] {args.model_path}")
         print(f"  [è©•ä¼°é–€æª»] Threshold = {args.threshold}")
    print("====================================================================\n")

if __name__ == "__main__":
    main()
