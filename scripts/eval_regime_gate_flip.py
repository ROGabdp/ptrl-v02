#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
================================================================================
Regime Gate Flip Evaluation
================================================================================
é€™å€‹è…³æœ¬è¨­è¨ˆç”¨ä¾†ã€Œé›¢ç·šã€è©•ä¼°ç°¡å–®çš„ Regime Gate æ˜¯å¦èƒ½æœ‰æ•ˆç¿»è½‰åå‘æŒ‡æ¨™å¹´ä»½çš„é æ¸¬ã€‚
ä¸éœ€è¦é‡æ–°è¨“ç·´æ¨¡åž‹ï¼Œç›´æŽ¥è®€å–ç¾æœ‰çš„ rolling HGB val_predictions.csvï¼Œ
ä¸¦çµåˆå¾ž Benchmark è¨ˆç®—çš„ Gate è¦å‰‡ (A, B, C, D) é€²è¡Œ score flipã€‚
================================================================================
"""

import os
import sys
import json
import argparse
import numpy as np
import pandas as pd
from glob import glob

ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT_DIR not in sys.path:
    sys.path.append(ROOT_DIR)

from src.eval.gate_utils import compute_gate_features, apply_regime_gates
try:
    from train_us_tech_buy_agent import fetch_all_stock_data, BENCHMARK
except ImportError:
    print("âŒ æ‰¾ä¸åˆ° train_us_tech_buy_agent æ¨¡çµ„ï¼Œè«‹ç¢ºå®šæ‚¨åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹åŸ·è¡Œã€‚")
    sys.exit(1)


def parse_args():
    parser = argparse.ArgumentParser(description="Regime Gate Flip é›¢ç·šè©•ä¼°è…³æœ¬")
    parser.add_argument('--ticker', type=str, default='GOOGL', help="ç›®æ¨™è‚¡ç¥¨ (é è¨­: GOOGL)")
    parser.add_argument('--pred-dir', type=str, help="[å‘å‰ç›¸å®¹] æŒ‡å‘å–®ä¸€ window year çš„ rolling è¼¸å‡ºç›®éŒ„")
    parser.add_argument('--pred-dirs', type=str, nargs='+', help="ç›´æŽ¥æŒ‡å®šå¤šå€‹ rolling è¼¸å‡ºç›®éŒ„ (ä¾‹å¦‚: windows/w3 windows/w5)")
    parser.add_argument('--base-dir', type=str, help="åŸºç¤Žç›®éŒ„ (ä¾‹å¦‚ output_rolling_grid/RUN_NAME/windows)")
    parser.add_argument('--windows', type=str, nargs='+', help="æ­é… base-dir ä½¿ç”¨ï¼ŒæŒ‡å®šè¦è©•ä¼°çš„ window_years (ä¾‹å¦‚ 3 5 7)")
    parser.add_argument('--topk-pct', type=float, default=5.0, help="è©•ä¼° Top K% çš„ Hitachi Rate (é è¨­: 5.0)")
    parser.add_argument('--output-dir', type=str, default='output_gate_eval', help="è¼¸å‡ºç›®éŒ„")
    parser.add_argument('--no-cache', action='store_true', help="å¼·åˆ¶é‡æ–°æ“·å–æ­·å²è³‡æ–™")
    return parser.parse_args()


def get_topk_hit_rate(df, score_col, target_col='y_true', k_pct=0.05):
    """æ ¹æ“šæŒ‡å®šçš„ score æ¬„ä½æŽ’åºï¼Œå–å‡ºå‰ k%ï¼Œè¨ˆç®— y_true çš„å¹³å‡ (Hit Rate)"""
    n_samples = len(df)
    k = max(1, int(n_samples * k_pct))
    
    # æŒ‰ç…§ score é™åºæŽ’
    df_sorted = df.sort_values(by=score_col, ascending=False)
    top_k_y = df_sorted.head(k)[target_col]
    return float(top_k_y.mean())


def main():
    args = parse_args()
    
    pred_dirs_dict = {}
    if args.base_dir and args.windows:
        for w in args.windows:
            label = f"w{w}" if not str(w).startswith("w") else str(w)
            pred_dirs_dict[label] = os.path.join(args.base_dir, label)
    elif args.pred_dirs:
        for d in args.pred_dirs:
            label = os.path.basename(os.path.normpath(d))
            pred_dirs_dict[label] = d
    elif args.pred_dir:
        label = os.path.basename(os.path.normpath(args.pred_dir))
        pred_dirs_dict[label] = args.pred_dir
    else:
        print("âŒ è«‹æä¾› --pred-dirs, æˆ–è€… --base-dir åŠ ä¸Š --windows")
        sys.exit(1)

    # 1. å–å¾— Benchmark æ­·å²è³‡æ–™ä¸¦è¨ˆç®— Gate ç‹€æ…‹
    print(f"ðŸ“¦ æ­£åœ¨ç²å– Benchmark ({BENCHMARK}) æœ€æ–°è³‡æ–™ä»¥è¨ˆç®— Regime Gates...")
    all_data = fetch_all_stock_data()
    benchmark_df = all_data.get(BENCHMARK)
    if benchmark_df is None:
         print(f"âŒ ç„¡æ³•å–å¾— Benchmark ({BENCHMARK}) è³‡æ–™")
         sys.exit(1)
         
    df_bmk_features = compute_gate_features(benchmark_df)
    df_gates = apply_regime_gates(df_bmk_features)
    df_gates['date'] = pd.to_datetime(df_gates['date']).dt.strftime('%Y-%m-%d')
    
    k_pct = args.topk_pct / 100.0
    gate_names = ['Gate_A', 'Gate_B', 'Gate_C', 'Gate_D']
    master_summary_long = []

    print(f"\nðŸš€ é–‹å§‹é€²è¡Œ Gate Flip è©•ä¼° (Top {args.topk_pct}%)")
    print(f"ç›®æ¨™ Windows: {list(pred_dirs_dict.keys())}")

    # 2. æŽƒæå„å€‹ window ç›®éŒ„
    for window_label, pred_dir in pred_dirs_dict.items():
        search_path = os.path.join(pred_dir, f"{args.ticker}_*")
        year_dirs = sorted(glob(search_path))
        
        if not year_dirs:
            print(f"  âš ï¸ [{window_label}] æ‰¾ä¸åˆ°ä»»ä½•é æ¸¬è³‡æ–™ï¼Œè·³éŽã€‚è·¯å¾‘: {pred_dir}")
            continue
            
        print(f"\nðŸŒ€ è™•ç† Window: {window_label} | æ‰¾åˆ° {len(year_dirs)} å€‹é©—è­‰å¹´ä»½")
        
        for y_dir in year_dirs:
            val_csv = os.path.join(y_dir, "val_predictions.csv")
            param_json = os.path.join(y_dir, "params.json")
            
            if not os.path.exists(val_csv):
                continue
                
            df_pred = pd.read_csv(val_csv)
            if len(df_pred) == 0:
                continue
                
            with open(param_json, 'r', encoding='utf-8') as f:
                 params = json.load(f)
                 val_y = params.get('val_year')
                 val_n = params.get('val_samples')
                 val_pos = params.get('val_pos_rate')
                 
            df_pred['date_str'] = pd.to_datetime(df_pred['date']).dt.strftime('%Y-%m-%d')
            
            df_merged = pd.merge(df_pred, df_gates, left_on='date_str', right_on='date', how='inner')
            if len(df_merged) == 0:
                print(f"  âš ï¸ {window_label} - {val_y} ç„¡æ³•èˆ‡å¤§ç›¤æ—¥æœŸå°é½Šï¼Œè·³éŽã€‚")
                continue
                
            hit_proba = get_topk_hit_rate(df_merged, 'y_proba', 'y_true', k_pct)
            df_merged['inv_proba'] = 1.0 - df_merged['y_proba']
            hit_invproba = get_topk_hit_rate(df_merged, 'inv_proba', 'y_true', k_pct)
            
            reversal_warning_orig = hit_invproba > hit_proba
            
            row_data = {
                'window_years': window_label,
                'year': val_y,
                'n_val': val_n,
                'pos_rate': val_pos,
                'topk_hit_proba': hit_proba,
                'topk_hit_invproba': hit_invproba,
                'reversal_warning_orig': reversal_warning_orig
            }
            
            for g in gate_names:
                 g_score_col = f'score_flip_{g}'
                 g_inv_score_col = f'inv_score_flip_{g}'
                 
                 # ç¿»è½‰é‚è¼¯
                 df_merged[g_score_col] = np.where(df_merged[g] == 'normal', 
                                                   df_merged['y_proba'], 
                                                   1.0 - df_merged['y_proba'])
                 df_merged[g_inv_score_col] = 1.0 - df_merged[g_score_col]
                 
                 hit_flip = get_topk_hit_rate(df_merged, g_score_col, 'y_true', k_pct)
                 hit_inv_flip = get_topk_hit_rate(df_merged, g_inv_score_col, 'y_true', k_pct)
                 
                 row_data[f'topk_hit_{g}'] = hit_flip
                 row_data[f'improv_{g}'] = hit_flip - hit_proba
                 row_data[f'flip_ratio_{g}'] = (df_merged[g] == 'reversal').mean()
                 row_data[f'reversal_after_{g}'] = hit_inv_flip > hit_flip
                 
            master_summary_long.append(row_data)

    if not master_summary_long:
        print("\nâŒ æ²’æœ‰å®Œæˆä»»ä½•å¹´ä»½çš„å½™æ•´è¨ˆç®—ã€‚")
        sys.exit(0)
        
    df_long = pd.DataFrame(master_summary_long)
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è¼¸å‡ºé•·è¡¨ (By Window Year)
    out_csv_long = os.path.join(args.output_dir, f"gate_eval_summary_{args.ticker}_by_window_year.csv")
    df_long.to_csv(out_csv_long, index=False)
    
    # 3. å»ºç«‹ Aggregated å½™æ•´è¡¨
    agg_data = []
    for w_label, df_w in df_long.groupby('window_years'):
        agg_row = {'window_years': w_label}
        agg_row['n_years_eval'] = len(df_w)
        agg_row['mean_topk_hit_proba'] = df_w['topk_hit_proba'].mean()
        agg_row['reversal_year_count_before'] = df_w['reversal_warning_orig'].sum()
        
        for g in gate_names:
            agg_row[f'mean_topk_hit_{g}'] = df_w[f'topk_hit_{g}'].mean()
            agg_row[f'reversal_year_count_after_{g}'] = df_w[f'reversal_after_{g}'].sum()
            agg_row[f'worst_year_drop_{g}'] = df_w[f'improv_{g}'].min()
            
        agg_data.append(agg_row)
        
    df_agg = pd.DataFrame(agg_data)
    out_csv_agg = os.path.join(args.output_dir, f"gate_eval_summary_{args.ticker}_window_agg.csv")
    df_agg.to_csv(out_csv_agg, index=False)
    
    print(f"\n{'='*80}\nâœ… Regime Gate Flip è·¨ Windows é›¢ç·šè©•ä¼°å®Œæˆï¼\n{'='*80}")
    print(f"ðŸ“‚ è©³ç´°å¹´åº¦é•·è¡¨å·²è¼¸å‡ºè‡³: {out_csv_long}")
    print(f"ðŸ“‚ Windows ç¶œåˆæ¯”è¼ƒè¡¨:  {out_csv_agg}")
    
    print("\nðŸ“Š å„ Window å½™æ•´æ¦‚è¦½ (Gate_C ç‚ºä¾‹):")
    for _, row in df_agg.iterrows():
        w = row['window_years']
        pct_b = row['mean_topk_hit_proba'] * 100
        pct_a = row['mean_topk_hit_Gate_C'] * 100
        rev_b = row['reversal_year_count_before']
        rev_a = row['reversal_year_count_after_Gate_C']
        drop = row['worst_year_drop_Gate_C'] * 100
        print(f"  [{w}] å‹çŽ‡: {pct_b:.1f}% -> {pct_a:.1f}% | åè½‰å¹´æ•¸: {rev_b} -> {rev_a} | æœ€æ…˜è² æ”¹å–„: {drop:+.1f}%")


if __name__ == '__main__':
    main()
