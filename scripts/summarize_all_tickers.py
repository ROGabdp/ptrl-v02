#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ‰¹æ¬¡æ»¾å‹•çµæžœå½™æ•´å·¥å…· (Summarize All Tickers)
è®€å– run_rolling_all_tickers ç”¢å‡ºçš„å„è‚¡ç¥¨ç›®éŒ„ä¸‹ä¹‹ rolling_summary.csv
ä¸¦é‡å°æŒ‡å®šçš„å¹´ä»½å€æ®µè¨ˆç®—ï¼šMean/Median AUCã€Top10 Hitã€Worst Gap åŠ Reversal è­¦å ±æ¬¡æ•¸ï¼Œ
æœ€å¾Œè¼¸å‡ºä¸€ä»½ç¸½è¡¨èˆ‡ JSON å¯è®“ä½¿ç”¨è€…ä¸€çœ¼æ¯”è¼ƒå“ªæª”è‚¡ç¥¨æœ€å…·å‹•èƒ½é æ¸¬ç©©å®šæ€§ã€‚
"""

import os
import argparse
import pandas as pd
import json
import numpy as np


def parse_args():
    parser = argparse.ArgumentParser(description="å½™æ•´æ‰¹æ¬¡ Rolling çš„æ‰€æœ‰è‚¡ç¥¨å¹´åº¦æˆæ•ˆè¡¨")
    parser.add_argument('--input-dir', type=str, default='output_rolling_all', 
                        help="åŒ…å«å„ Ticker ç›®éŒ„çš„è¼¸å…¥æ ¹ç›®éŒ„ã€‚é è¨­: output_rolling_all")
    parser.add_argument('--output-dir', type=str, default='output_rolling_all', 
                        help="ç¸½è¡¨è¼¸å‡ºçš„å­˜æ”¾ç›®éŒ„ã€‚é è¨­åŒ input-dir")
    parser.add_argument('--years-from', type=int, default=2017, help="å½™æ•´èµ·å§‹å¹´ä»½ (é è¨­: 2017)")
    parser.add_argument('--years-to', type=int, default=2030, help="å½™æ•´çµæŸå¹´ä»½ (é è¨­: 2030)")
    parser.add_argument('--topk', type=int, default=10, help="åƒè€ƒçš„åˆ†ä½æ•¸ã€‚ç›®å‰ rolling è‡ªå¸¶ top5 / top10")
    parser.add_argument('--reversal-gap-margin', type=float, default=0.10, 
                        help="åè½‰è¨ˆç®—æ¢ä»¶ä¹‹ gap å®¹å¿ã€‚è‹¥ summary ä¸­ç„¡ reversal_warning æ‰é‡ç®—")
    parser.add_argument('--sort-by', type=str, default='mean_top10_hit_proba', 
                        choices=['reversal_year_count_v2', 'mean_top10_hit_proba', 'mean_roc_auc', 'worst_top10_gap'],
                        help="ç¸½è¡¨è¼¸å‡ºçš„é è¨­æŽ’åºæ¬„ä½")
    return parser.parse_args()


def safe_mean(series):
    return float(series.mean()) if not series.empty else np.nan

def safe_median(series):
    return float(series.median()) if not series.empty else np.nan

def safe_min(series):
    return float(series.min()) if not series.empty else np.nan


def main():
    args = parse_args()
    print("====================================================================")
    print("ðŸ“Š Summarizing All Tickers Rolling Performance")
    print("====================================================================")
    
    if not os.path.exists(args.input_dir):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥ç›®éŒ„: {args.input_dir}")
        return
        
    os.makedirs(args.output_dir, exist_ok=True)
    
    tickers_results = []
    skipped_tickers = []
    
    # æŽƒæè¼¸å…¥ç›®éŒ„åº•ä¸‹æ‰€æœ‰çš„å­ç›®éŒ„ (ç†æƒ³æƒ…æ³: æ¯å€‹åç¨±éƒ½æ˜¯ä¸€å€‹ Ticker)
    for ticker_item in sorted(os.listdir(args.input_dir)):
        ticker_dir = os.path.join(args.input_dir, ticker_item)
        
        # æŽ’é™¤éžç›®éŒ„ç‰©ä»¶
        if not os.path.isdir(ticker_dir):
            continue
            
        csv_path = os.path.join(ticker_dir, "rolling_summary.csv")
        if not os.path.exists(csv_path):
            # ä¸æ˜¯ Ticker ç›®éŒ„ï¼Œå¯èƒ½åªæ˜¯å¤–å±¤çš„æª”æ¡ˆ
            continue
            
        ticker = ticker_item
        df = pd.read_csv(csv_path)
        
        if df.empty:
            skipped_tickers.append({"ticker": ticker, "reason": "Empty CSV dataset"})
            continue
            
        # ç¯©é¸è¦æ±‚çš„å¹´ä»½å€é–“
        df['val_year'] = df['val_year'].astype(int)
        mask = (df['val_year'] >= args.years_from) & (df['val_year'] <= args.years_to)
        df_filt = df[mask].copy()
        
        if df_filt.empty:
            skipped_tickers.append({
                "ticker": ticker, 
                "reason": f"No data in year range {args.years_from}-{args.years_to}"
            })
            continue
            
        n_years = len(df_filt)
        
        # å‹•æ…‹åˆ¤å®šæœ‰ç„¡å…§å»º V2 reversal æ¬„ä½
        if 'reversal_warning' in df_filt.columns:
            has_reversals = df_filt['reversal_warning'] == True
        else:
            # Fallback èˆŠç‰ˆçš„é‡ç®— (å‡è¨­ä»æœ‰ top10_gap èˆ‡ roc_auc)
            is_gap_fail = (df_filt['top10_gap'] <= -args.reversal_gap_margin)
            is_roc_fail = (df_filt['roc_auc'] < 0.5)
            has_reversals = is_gap_fail | is_roc_fail
            
        rev_count = has_reversals.sum()
        rev_years = df_filt.loc[has_reversals, 'val_year'].astype(str).tolist()
        
        # å°‹æ‰¾ ROC AUC æœ€å·®çš„ä¸€å¹´
        worst_auc_idx = df_filt['roc_auc'].idxmin() if 'roc_auc' in df_filt.columns else None
        worst_roc_val = df_filt.loc[worst_auc_idx, 'roc_auc'] if worst_auc_idx is not None else np.nan
        worst_roc_yr = df_filt.loc[worst_auc_idx, 'val_year'] if worst_auc_idx is not None else np.nan
        
        # å°‹æ‰¾ Top10 Gap æœ€å·®çš„ä¸€å¹´ (æœ€å°)
        gap_col = f"top{args.topk}_gap"
        prob_col = f"top{args.topk}_hit_proba"
        top5_gap_col = "top5_gap"
        top5_prob_col = "top5_hit_proba"
        
        worst_gap_val, worst_gap_yr = np.nan, np.nan
        if gap_col in df_filt.columns:
            worst_gap_idx = df_filt[gap_col].idxmin()
            worst_gap_val = df_filt.loc[worst_gap_idx, gap_col]
            worst_gap_yr = df_filt.loc[worst_gap_idx, 'val_year']
            
        # æ‰“åŒ… Single Ticker Aggregate Metrics
        metrics = {
            "ticker": ticker,
            "n_years_evaluated": n_years,
            "mean_roc_auc": safe_mean(df_filt.get('roc_auc', pd.Series(dtype=float))),
            "median_roc_auc": safe_median(df_filt.get('roc_auc', pd.Series(dtype=float))),
            "mean_pr_auc": safe_mean(df_filt.get('pr_auc', pd.Series(dtype=float))),
            "median_pr_auc": safe_median(df_filt.get('pr_auc', pd.Series(dtype=float))),
            f"mean_{prob_col}": safe_mean(df_filt.get(prob_col, pd.Series(dtype=float))),
            f"median_{prob_col}": safe_median(df_filt.get(prob_col, pd.Series(dtype=float))),
            f"mean_{gap_col}": safe_mean(df_filt.get(gap_col, pd.Series(dtype=float))),
            f"worst_{gap_col}": float(worst_gap_val) if pd.notna(worst_gap_val) else np.nan,
            "reversal_year_count_v2": int(rev_count),
            "reversal_years_list_v2": ",".join(rev_years) if rev_years else "None",
            "worst_year_by_roc_auc": f"{worst_roc_yr} ({worst_roc_val:.3f})" if pd.notna(worst_roc_yr) else "N/A",
            f"worst_year_by_{gap_col}": f"{worst_gap_yr} ({worst_gap_val:.3f})" if pd.notna(worst_gap_yr) else "N/A",
        }
        
        # è‹¥æœ‰ Top5 æ¬„ä½ä¸€ä½µåŒ¯å‡ºå¯é¸è³‡è¨Š
        if top5_prob_col in df_filt.columns:
             metrics[f"mean_{top5_prob_col}"] = safe_mean(df_filt[top5_prob_col])
        if top5_gap_col in df_filt.columns:
             metrics[f"mean_{top5_gap_col}"] = safe_mean(df_filt[top5_gap_col])
             
        tickers_results.append(metrics)
        print(f"  âœ… è™•ç†å®Œæˆ: {ticker} (å½™æ•´ {n_years} ç­†å¹´åº¦ç´€éŒ„)")

    print("-" * 68)
    
    if len(tickers_results) == 0:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æˆåŠŸçš„ Ticker ç¸½çµå¯ä»¥è¼¸å‡ºã€‚è«‹ç¢ºä¿å·²ç¶“å…ˆè·‘éŽ run_rolling_all_tickers.pyã€‚")
        return
        
    # çµ„åˆ DataFrame èˆ‡æŽ’åº
    df_out = pd.DataFrame(tickers_results)
    
    # æ±ºå®šæŽ’åˆ—é †åº (reversal_count å‡åºï¼Œå…¶ä»–å¯èƒ½ç‚ºé™åºè¼ƒå¥½)
    ascending = True if args.sort_by == 'reversal_year_count_v2' else False
    if args.sort_by in df_out.columns:
        df_out = df_out.sort_values(by=[args.sort_by, 'ticker'], ascending=[ascending, True])
    
    # æº–å‚™ JSON Output çš„åŒ…è£
    final_output = {
        "summary_params": {
            "years_from": args.years_from,
            "years_to": args.years_to,
            "topk_used": args.topk,
            "sort_by": args.sort_by
        },
        "skipped_tickers": skipped_tickers,
        "tickers_data": df_out.to_dict(orient="records")
    }
    
    csv_path = os.path.join(args.output_dir, "all_tickers_summary.csv")
    json_path = os.path.join(args.output_dir, "all_tickers_summary.json")
    
    df_out.to_csv(csv_path, index=False)
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(final_output, f, indent=4, ensure_ascii=False)
        
    print(f"ðŸŽ‰ æˆåŠŸè¼¸å‡ºè·¨ Ticker å¤§è¡¨æ¯”å°!")
    print(f"ðŸ‘‰ JSON Path: {json_path}")
    print(f"ðŸ‘‰ CSV Path:  {csv_path}")
    
    # çµ‚ç«¯å°å‡ºä¸€ä»½ç¸®æ¸›ç‰ˆçš„é‡é»žè¡¨æ ¼
    cols_to_print = ['ticker', 'n_years_evaluated', f'mean_{prob_col}', f'worst_{gap_col}', 
                     'reversal_year_count_v2', 'reversal_years_list_v2']
    valid_cols = [c for c in cols_to_print if c in df_out.columns]
    print("\nðŸŽ¯ [å¿«é€Ÿé è¦½]")
    print(df_out[valid_cols].to_string(index=False))
    print("\n====================================================================")


if __name__ == "__main__":
    main()
